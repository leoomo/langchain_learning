# æ™ºèƒ½é¡¾é—®ç³»ç»Ÿå¼€å‘æŒ‡å—

## ğŸ“‹ æ¨¡å—æ¦‚è¿°

### ğŸ¯ ç³»ç»Ÿå®šä½
æ™ºèƒ½é¡¾é—®ç³»ç»Ÿæ˜¯æ™ºèƒ½é’“é±¼ç”Ÿæ€ç³»ç»Ÿçš„æ ¸å¿ƒå¤§è„‘ï¼Œè´Ÿè´£æ•´åˆé±¼ç±»çŸ¥è¯†ã€è£…å¤‡æ¨èã€è£…å¤‡å¯¹æ¯”ç­‰æ‰€æœ‰å­ç³»ç»Ÿï¼Œé€šè¿‡æ™ºèƒ½å·¥ä½œæµç¼–æ’å’Œè·¨ç³»ç»ŸååŒåˆ†æï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ç«™å¼çš„ä¸“ä¸šé’“é±¼æŒ‡å¯¼æœåŠ¡ã€‚è¯¥ç³»ç»Ÿæ˜¯æ•´ä¸ªç”Ÿæ€ç³»ç»Ÿçš„å…¥å£å’Œåè°ƒä¸­å¿ƒï¼Œå®ç°äº†ä»å•ä¸€åŠŸèƒ½åˆ°ç»¼åˆæœåŠ¡çš„æ™ºèƒ½åŒ–å‡çº§ã€‚

### ğŸ” æ ¸å¿ƒä»·å€¼ä¸»å¼ 
- **ä¸€ç«™å¼æœåŠ¡**: æ•´åˆæ‰€æœ‰å­ç³»ç»ŸåŠŸèƒ½ï¼Œæä¾›å®Œæ•´çš„é’“é±¼è§£å†³æ–¹æ¡ˆ
- **æ™ºèƒ½åè°ƒ**: è·¨ç³»ç»ŸååŒåˆ†æï¼Œæä¾›æœ€ä¼˜çš„ç»¼åˆå»ºè®®
- **ä¸“ä¸šæŒ‡å¯¼**: åŸºäºä¸“ä¸šçŸ¥è¯†å›¾è°±çš„æ·±åº¦åˆ†æå’ŒæŒ‡å¯¼
- **ä¸ªæ€§åŒ–å·¥åŠ**: æ ¹æ®ç”¨æˆ·ç‰¹å¾æä¾›é«˜åº¦ä¸ªæ€§åŒ–çš„æœåŠ¡

### ğŸ—ï¸ ç³»ç»Ÿä¾èµ–
- **é±¼ç±»çŸ¥è¯†ç³»ç»Ÿ**: æä¾›é±¼ç§ä¹ æ€§ã€é’“é±¼ç­–ç•¥ç­‰ä¸“ä¸šçŸ¥è¯†
- **è£…å¤‡æ¨èç³»ç»Ÿ**: æä¾›ä¸ªæ€§åŒ–è£…å¤‡æ¨èå’Œæ­é…å»ºè®®
- **è£…å¤‡å¯¹æ¯”ç³»ç»Ÿ**: æä¾›è¯¦ç»†çš„è£…å¤‡å¯¹æ¯”åˆ†æå’Œå‡çº§å»ºè®®
- **åŸºç¡€è®¾æ–½å±‚**: å…±äº«æœåŠ¡ç®¡ç†ã€ç¼“å­˜ã€é…ç½®ç­‰åŸºç¡€èƒ½åŠ›

## ğŸ¯ é¢†åŸŸæ¨¡å‹è®¾è®¡

### æ ¸å¿ƒå®ä½“æ¨¡å‹

#### 1. æ™ºèƒ½é¡¾é—®å®ä½“ (IntelligentAdvisor)
```python
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any, Tuple
from enum import Enum
from datetime import datetime

class AdvisoryType(Enum):
    """é¡¾é—®ç±»å‹æšä¸¾"""
    FISHING_GUIDANCE = "fishing_guidance"           # é’“é±¼æŒ‡å¯¼
    EQUIPMENT_CONSULTATION = "equipment_consultation" # è£…å¤‡å’¨è¯¢
    STRATEGY_PLANNING = "strategy_planning"         # ç­–ç•¥è§„åˆ’
    COMPREHENSIVE_ANALYSIS = "comprehensive_analysis" # ç»¼åˆåˆ†æ
    TROUBLESHOOTING = "troubleshooting"             # é—®é¢˜è§£å†³

class QueryComplexity(Enum):
    """æŸ¥è¯¢å¤æ‚åº¦æšä¸¾"""
    SIMPLE = "simple"                    # ç®€å•æŸ¥è¯¢
    MODERATE = "moderate"                # ä¸­ç­‰å¤æ‚åº¦
    COMPLEX = "complex"                  # å¤æ‚æŸ¥è¯¢
    VERY_COMPLEX = "very_complex"        # éå¸¸å¤æ‚

class IntentType(Enum):
    """æ„å›¾ç±»å‹æšä¸¾"""
    KNOWLEDGE_QUERY = "knowledge_query"     # çŸ¥è¯†æŸ¥è¯¢
    EQUIPMENT_RECOMMENDATION = "equipment_recommendation"  # è£…å¤‡æ¨è
    EQUIPMENT_COMPARISON = "equipment_comparison"        # è£…å¤‡å¯¹æ¯”
    STRATEGY_ADVICE = "strategy_advice"      # ç­–ç•¥å»ºè®®
    SCENARIO_ANALYSIS = "scenario_analysis"  # åœºæ™¯åˆ†æ
    GENERAL_CONSULTATION = "general_consultation"  # ä¸€èˆ¬å’¨è¯¢

@dataclass
class UserIntent:
    """ç”¨æˆ·æ„å›¾"""
    primary_intent: IntentType              # ä¸»è¦æ„å›¾
    secondary_intents: List[IntentType]     # æ¬¡è¦æ„å›¾
    entities: Dict[str, Any]               # å®ä½“ä¿¡æ¯
    confidence: float                      # ç½®ä¿¡åº¦
    complexity: QueryComplexity             # æŸ¥è¯¢å¤æ‚åº¦
    context_requirements: List[str]         # ä¸Šä¸‹æ–‡éœ€æ±‚

@dataclass
class AdvisoryContext:
    """é¡¾é—®ä¸Šä¸‹æ–‡"""
    user_id: Optional[str]                 # ç”¨æˆ·ID
    conversation_history: List[Dict[str, Any]]  # å¯¹è¯å†å²
    user_profile: Optional[Dict[str, Any]]  # ç”¨æˆ·ç”»åƒ
    current_session: Dict[str, Any]         # å½“å‰ä¼šè¯ä¿¡æ¯
    environment_info: Dict[str, Any]        # ç¯å¢ƒä¿¡æ¯ï¼ˆå¤©æ°”ã€åœ°ç‚¹ç­‰ï¼‰
    temporal_context: Dict[str, Any]        # æ—¶é—´ä¸Šä¸‹æ–‡

@dataclass
class AdvisoryPlan:
    """é¡¾é—®è®¡åˆ’"""
    advisory_id: str                       # é¡¾é—®ID
    intent: UserIntent                      # ç”¨æˆ·æ„å›¾
    workflow_steps: List[Dict[str, Any]]   # å·¥ä½œæµæ­¥éª¤
    required_services: List[str]            # éœ€è¦çš„æœåŠ¡
    execution_strategy: str                 # æ‰§è¡Œç­–ç•¥
    estimated_time: float                  # é¢„ä¼°æ—¶é—´
    created_at: datetime = field(default_factory=datetime.now)

@dataclass
class AdvisoryResult:
    """é¡¾é—®ç»“æœ"""
    advisory_id: str                       # é¡¾é—®ID
    success: bool                          # æ˜¯å¦æˆåŠŸ
    primary_answer: str                    # ä¸»è¦ç­”æ¡ˆ
    detailed_analysis: Dict[str, Any]      # è¯¦ç»†åˆ†æ
    recommendations: List[Dict[str, Any]]  # æ¨èå»ºè®®
    follow_up_questions: List[str]         # åç»­é—®é¢˜
    confidence_score: float                # ç½®ä¿¡åº¦è¯„åˆ†
    execution_time: float                  # æ‰§è¡Œæ—¶é—´
    service_contributions: Dict[str, Any]  # æœåŠ¡è´¡çŒ®åº¦
    created_at: datetime = field(default_factory=datetime.now)
```

#### 2. å·¥ä½œæµç¼–æ’æ¨¡å‹ (WorkflowOrchestrator)
```python
class WorkflowStepType(Enum):
    """å·¥ä½œæµæ­¥éª¤ç±»å‹"""
    INTENT_ANALYSIS = "intent_analysis"           # æ„å›¾åˆ†æ
    KNOWLEDGE_RETRIEVAL = "knowledge_retrieval"   # çŸ¥è¯†æ£€ç´¢
    DATA_ANALYSIS = "data_analysis"               # æ•°æ®åˆ†æ
    SERVICE_COORDINATION = "service_coordination" # æœåŠ¡åè°ƒ
    RESULT_SYNTHESIS = "result_synthesis"         # ç»“æœåˆæˆ
    QUALITY_CHECK = "quality_check"               # è´¨é‡æ£€æŸ¥

@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥éª¤"""
    step_id: str                           # æ­¥éª¤ID
    step_type: WorkflowStepType            # æ­¥éª¤ç±»å‹
    description: str                       # æ­¥éª¤æè¿°
    required_services: List[str]           # éœ€è¦çš„æœåŠ¡
    input_data: Dict[str, Any]             # è¾“å…¥æ•°æ®
    expected_output: Dict[str, Any]        # æœŸæœ›è¾“å‡º
    execution_order: int                   # æ‰§è¡Œé¡ºåº
    dependencies: List[str]                # ä¾èµ–æ­¥éª¤
    timeout: float                         # è¶…æ—¶æ—¶é—´
    retry_count: int = 3                   # é‡è¯•æ¬¡æ•°

@dataclass
class WorkflowExecution:
    """å·¥ä½œæµæ‰§è¡Œ"""
    execution_id: str                      # æ‰§è¡ŒID
    plan: AdvisoryPlan                     # é¡¾é—®è®¡åˆ’
    current_step: int                      # å½“å‰æ­¥éª¤
    completed_steps: List[str]             # å·²å®Œæˆæ­¥éª¤
    step_results: Dict[str, Any]           # æ­¥éª¤ç»“æœ
    execution_status: str                  # æ‰§è¡ŒçŠ¶æ€
    start_time: datetime                   # å¼€å§‹æ—¶é—´
    end_time: Optional[datetime] = None    # ç»“æŸæ—¶é—´
    error_info: Optional[Dict[str, Any]] = None  # é”™è¯¯ä¿¡æ¯
```

### æ ¸å¿ƒæœåŠ¡æ¨¡å‹

#### 1. æ™ºèƒ½é¡¾é—®æœåŠ¡ (IntelligentAdvisorService)
```python
class IntelligentAdvisorService:
    """æ™ºèƒ½é¡¾é—®æœåŠ¡"""

    def __init__(self,
                 intent_classifier: 'IntentClassifier',
                 workflow_orchestrator: 'WorkflowOrchestrator',
                 knowledge_integrator: 'KnowledgeIntegrator',
                 result_synthesizer: 'ResultSynthesizer',
                 service_manager: 'ServiceManager'):
        self.intent_classifier = intent_classifier
        self.workflow_orchestrator = workflow_orchestrator
        self.knowledge_integrator = knowledge_integrator
        self.result_synthesizer = result_synthesizer
        self.service_manager = service_manager
        self.advisory_cache = AdvisoryCache()
        self.performance_monitor = PerformanceMonitor()

    async def provide_comprehensive_advice(self, user_query: str,
                                         context: AdvisoryContext) -> AdvisoryResult:
        """æä¾›ç»¼åˆå»ºè®®"""
        try:
            start_time = datetime.now()

            # 1. æ„å›¾è¯†åˆ«
            logger.info(f"å¼€å§‹åˆ†æç”¨æˆ·æŸ¥è¯¢: {user_query}")
            intent = await self.intent_classifier.classify_intent(user_query, context)

            # 2. æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(user_query, intent, context)
            cached_result = self.advisory_cache.get(cache_key)
            if cached_result:
                logger.info("è¿”å›ç¼“å­˜ç»“æœ")
                return cached_result

            # 3. ç”Ÿæˆé¡¾é—®è®¡åˆ’
            plan = await self._generate_advisory_plan(intent, context)

            # 4. æ‰§è¡Œå·¥ä½œæµ
            execution = await self.workflow_orchestrator.execute_workflow(plan, context)

            # 5. åˆæˆç»“æœ
            result = await self.result_synthesizer.synthesize_result(
                execution, intent, context
            )

            # 6. è´¨é‡æ£€æŸ¥
            quality_score = await self._perform_quality_check(result, intent)
            result.confidence_score = quality_score

            # 7. ç¼“å­˜ç»“æœ
            execution_time = (datetime.now() - start_time).total_seconds()
            result.execution_time = execution_time

            self.advisory_cache.set(cache_key, result)

            # 8. æ€§èƒ½ç›‘æ§
            self.performance_monitor.record_advisory_execution(
                intent, execution_time, quality_score
            )

            logger.info(f"é¡¾é—®å»ºè®®ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {execution_time:.2f}sï¼Œç½®ä¿¡åº¦ {quality_score:.2f}")
            return result

        except Exception as e:
            logger.error(f"ç»¼åˆå»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            return self._create_error_result(str(e), user_query)

    async def analyze_fishing_scenario(self, scenario: Dict[str, Any],
                                    context: AdvisoryContext) -> AdvisoryResult:
        """åˆ†æé’“é±¼åœºæ™¯"""
        try:
            # æ„å»ºåœºæ™¯æŸ¥è¯¢
            scenario_query = self._build_scenario_query(scenario)

            # è®¾ç½®åœºæ™¯ç‰¹å®šçš„ä¸Šä¸‹æ–‡
            scenario_context = self._enrich_context_with_scenario(context, scenario)

            # æ‰§è¡Œç»¼åˆåˆ†æ
            result = await self.provide_comprehensive_advice(
                scenario_query, scenario_context
            )

            # æ·»åŠ åœºæ™¯ç‰¹å®šçš„åˆ†æ
            result.detailed_analysis['scenario_analysis'] = await self._analyze_scenario_details(
                scenario, result.service_contributions
            )

            return result

        except Exception as e:
            logger.error(f"é’“é±¼åœºæ™¯åˆ†æå¤±è´¥: {e}")
            return self._create_error_result(str(e), "åœºæ™¯åˆ†æ")

    async def recommend_complete_solution(self, requirements: Dict[str, Any],
                                       context: AdvisoryContext) -> AdvisoryResult:
        """æ¨èå®Œæ•´è§£å†³æ–¹æ¡ˆ"""
        try:
            # æ„å»ºè§£å†³æ–¹æ¡ˆæŸ¥è¯¢
            solution_query = self._build_solution_query(requirements)

            # æ‰§è¡Œç»¼åˆå»ºè®®
            result = await self.provide_comprehensive_advice(
                solution_query, context
            )

            # ç”Ÿæˆç»“æ„åŒ–è§£å†³æ–¹æ¡ˆ
            result.detailed_analysis['complete_solution'] = await self._generate_complete_solution(
                requirements, result.service_contributions
            )

            return result

        except Exception as e:
            logger.error(f"å®Œæ•´è§£å†³æ–¹æ¡ˆæ¨èå¤±è´¥: {e}")
            return self._create_error_result(str(e), "è§£å†³æ–¹æ¡ˆæ¨è")

    async def _generate_advisory_plan(self, intent: UserIntent,
                                    context: AdvisoryContext) -> AdvisoryPlan:
        """ç”Ÿæˆé¡¾é—®è®¡åˆ’"""
        plan_id = self._generate_plan_id()

        # æ ¹æ®æ„å›¾å¤æ‚åº¦é€‰æ‹©å·¥ä½œæµæ¨¡æ¿
        workflow_template = self._select_workflow_template(intent)

        # ä¸ªæ€§åŒ–å·¥ä½œæµæ­¥éª¤
        workflow_steps = await self._personalize_workflow_steps(
            workflow_template, intent, context
        )

        # ç¡®å®šéœ€è¦çš„æœåŠ¡
        required_services = self._identify_required_services(workflow_steps)

        # ä¼°ç®—æ‰§è¡Œæ—¶é—´
        estimated_time = self._estimate_execution_time(workflow_steps, intent.complexity)

        return AdvisoryPlan(
            advisory_id=plan_id,
            intent=intent,
            workflow_steps=workflow_steps,
            required_services=required_services,
            execution_strategy=self._determine_execution_strategy(intent),
            estimated_time=estimated_time
        )

    async def _personalize_workflow_steps(self, template: List[Dict[str, Any]],
                                        intent: UserIntent,
                                        context: AdvisoryContext) -> List[Dict[str, Any]]:
        """ä¸ªæ€§åŒ–å·¥ä½œæµæ­¥éª¤"""
        personalized_steps = []

        for step_template in template:
            step = WorkflowStep(
                step_id=self._generate_step_id(),
                step_type=WorkflowStepType(step_template['type']),
                description=step_template['description'],
                required_services=step_template['services'],
                input_data={},
                expected_output=step_template['expected_output'],
                execution_order=step_template['order'],
                dependencies=step_template.get('dependencies', []),
                timeout=step_template.get('timeout', 30.0)
            )

            # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´æ­¥éª¤
            personalized_step = await self._adjust_step_for_context(step, intent, context)
            personalized_steps.append(personalized_step)

        return personalized_steps

    def _select_workflow_template(self, intent: UserIntent) -> List[Dict[str, Any]]:
        """é€‰æ‹©å·¥ä½œæµæ¨¡æ¿"""
        templates = {
            IntentType.KNOWLEDGE_QUERY: [
                {
                    'type': 'intent_analysis',
                    'description': 'åˆ†ææŸ¥è¯¢æ„å›¾',
                    'services': ['intent_classifier'],
                    'expected_output': {'intent_confirmed': True},
                    'order': 1
                },
                {
                    'type': 'knowledge_retrieval',
                    'description': 'æ£€ç´¢ç›¸å…³çŸ¥è¯†',
                    'services': ['fish_knowledge_service'],
                    'expected_output': {'knowledge_data': []},
                    'order': 2,
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'result_synthesis',
                    'description': 'åˆæˆå›ç­”ç»“æœ',
                    'services': ['result_synthesizer'],
                    'expected_output': {'final_answer': ''},
                    'order': 3,
                    'dependencies': ['knowledge_retrieval']
                }
            ],
            IntentType.EQUIPMENT_RECOMMENDATION: [
                {
                    'type': 'intent_analysis',
                    'description': 'åˆ†æè£…å¤‡æ¨èéœ€æ±‚',
                    'services': ['intent_classifier'],
                    'expected_output': {'requirements_extracted': True},
                    'order': 1
                },
                {
                    'type': 'knowledge_retrieval',
                    'description': 'è·å–ç”¨æˆ·åå¥½å’Œå†å²æ•°æ®',
                    'services': ['user_preference_service', 'fish_knowledge_service'],
                    'expected_output': {'user_context': {}},
                    'order': 2,
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'service_coordination',
                    'description': 'è°ƒç”¨è£…å¤‡æ¨èæœåŠ¡',
                    'services': ['recommendation_engine'],
                    'expected_output': {'equipment_recommendations': []},
                    'order': 3,
                    'dependencies': ['knowledge_retrieval']
                },
                {
                    'type': 'result_synthesis',
                    'description': 'ç”Ÿæˆæ¨èå»ºè®®',
                    'services': ['result_synthesizer'],
                    'expected_output': {'recommendation_result': {}},
                    'order': 4,
                    'dependencies': ['service_coordination']
                }
            ],
            IntentType.EQUIPMENT_COMPARISON: [
                {
                    'type': 'intent_analysis',
                    'description': 'åˆ†æè£…å¤‡å¯¹æ¯”éœ€æ±‚',
                    'services': ['intent_classifier'],
                    'expected_output': {'comparison_requirements': {}},
                    'order': 1
                },
                {
                    'type': 'data_analysis',
                    'description': 'åˆ†æè£…å¤‡è§„æ ¼å‚æ•°',
                    'services': ['specification_analyzer'],
                    'expected_output': {'spec_analysis': {}},
                    'order': 2,
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'service_coordination',
                    'description': 'æ‰§è¡Œè£…å¤‡å¯¹æ¯”åˆ†æ',
                    'services': ['comparison_engine'],
                    'expected_output': {'comparison_result': {}},
                    'order': 3,
                    'dependencies': ['data_analysis']
                },
                {
                    'type': 'result_synthesis',
                    'description': 'ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š',
                    'services': ['result_synthesizer'],
                    'expected_output': {'comparison_report': {}},
                    'order': 4,
                    'dependencies': ['service_coordination']
                }
            ],
            IntentType.STRATEGY_ADVICE: [
                {
                    'type': 'intent_analysis',
                    'description': 'åˆ†æç­–ç•¥å’¨è¯¢éœ€æ±‚',
                    'services': ['intent_classifier'],
                    'expected_output': {'strategy_requirements': {}},
                    'order': 1
                },
                {
                    'type': 'knowledge_retrieval',
                    'description': 'è·å–é’“é±¼ç­–ç•¥çŸ¥è¯†',
                    'services': ['fish_knowledge_service', 'strategy_service'],
                    'expected_output': {'strategy_knowledge': {}},
                    'order': 2,
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'data_analysis',
                    'description': 'åˆ†æç¯å¢ƒå’Œæ¡ä»¶',
                    'services': ['weather_service', 'environment_analyzer'],
                    'expected_output': {'environment_analysis': {}},
                    'order': 2,  # å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'service_coordination',
                    'description': 'ç”Ÿæˆä¸ªæ€§åŒ–ç­–ç•¥',
                    'services': ['strategy_engine'],
                    'expected_output': {'strategy_recommendations': []},
                    'order': 4,
                    'dependencies': ['knowledge_retrieval', 'data_analysis']
                },
                {
                    'type': 'result_synthesis',
                    'description': 'åˆæˆç­–ç•¥å»ºè®®',
                    'services': ['result_synthesizer'],
                    'expected_output': {'strategy_advice': {}},
                    'order': 5,
                    'dependencies': ['service_coordination']
                }
            ],
            IntentType.SCENARIO_ANALYSIS: [
                {
                    'type': 'intent_analysis',
                    'description': 'åˆ†æåœºæ™¯éœ€æ±‚',
                    'services': ['intent_classifier'],
                    'expected_output': {'scenario_understood': True},
                    'order': 1
                },
                {
                    'type': 'knowledge_retrieval',
                    'description': 'è·å–åœºæ™¯ç›¸å…³çŸ¥è¯†',
                    'services': ['fish_knowledge_service', 'equipment_service'],
                    'expected_output': {'scenario_knowledge': {}},
                    'order': 2,
                    'dependencies': ['intent_analysis']
                },
                {
                    'type': 'service_coordination',
                    'description': 'å¤šç³»ç»ŸååŒåˆ†æ',
                    'services': ['recommendation_engine', 'comparison_engine', 'strategy_service'],
                    'expected_output': {'multi_system_analysis': {}},
                    'order': 3,
                    'dependencies': ['knowledge_retrieval']
                },
                {
                    'type': 'result_synthesis',
                    'description': 'ç”Ÿæˆåœºæ™¯åˆ†ææŠ¥å‘Š',
                    'services': ['result_synthesizer'],
                    'expected_output': {'scenario_report': {}},
                    'order': 4,
                    'dependencies': ['service_coordination']
                }
            ]
        }

        # å¤„ç†å¤åˆæ„å›¾
        if len(intent.secondary_intents) > 0:
            return self._create_complex_workflow(intent)

        return templates.get(intent.primary_intent, templates[IntentType.GENERAL_CONSULTATION])

    def _create_complex_workflow(self, intent: UserIntent) -> List[Dict[str, Any]]:
        """åˆ›å»ºå¤åˆæ„å›¾å·¥ä½œæµ"""
        base_workflow = [
            {
                'type': 'intent_analysis',
                'description': 'åˆ†æå¤åˆæ„å›¾',
                'services': ['intent_classifier'],
                'expected_output': {'complex_intent_resolved': True},
                'order': 1
            }
        ]

        # ä¸ºæ¯ä¸ªæ„å›¾æ·»åŠ ç›¸åº”çš„å¤„ç†æ­¥éª¤
        step_offset = 1
        for i, sec_intent in enumerate(intent.secondary_intents):
            intent_workflow = self._select_workflow_template(
                UserIntent(primary_intent=sec_intent, secondary_intents=[],
                          entities={}, confidence=0.8, complexity=QueryComplexity.MODERATE,
                          context_requirements=[])
            )

            for step in intent_workflow:
                step['order'] += step_offset + i * 10

            base_workflow.extend(intent_workflow)

        # æ·»åŠ æœ€ç»ˆç»“æœåˆæˆæ­¥éª¤
        base_workflow.append({
            'type': 'result_synthesis',
            'description': 'åˆæˆå¤åˆæ„å›¾ç»“æœ',
            'services': ['result_synthesizer'],
            'expected_output': {'complex_result': {}},
            'order': 100,
            'dependencies': ['step_1']  # ä¾èµ–æ„å›¾åˆ†æ
        })

        return base_workflow

    async def _perform_quality_check(self, result: AdvisoryResult,
                                    intent: UserIntent) -> float:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥"""
        quality_factors = []

        # ç­”æ¡ˆå®Œæ•´æ€§æ£€æŸ¥
        completeness_score = self._check_answer_completeness(result)
        quality_factors.append(('completeness', completeness_score, 0.3))

        # ç›¸å…³æ€§æ£€æŸ¥
        relevance_score = await self._check_answer_relevance(result, intent)
        quality_factors.append(('relevance', relevance_score, 0.4))

        # ä¸“ä¸šæ€§æ£€æŸ¥
        professionalism_score = self._check_professionalism(result)
        quality_factors.append(('professionalism', professionalism_score, 0.2))

        # å¯è¯»æ€§æ£€æŸ¥
        readability_score = self._check_readability(result)
        quality_factors.append(('readability', readability_score, 0.1))

        # è®¡ç®—åŠ æƒæ€»åˆ†
        total_score = sum(score * weight for factor, score, weight in quality_factors)

        return min(total_score, 100.0)

    def _check_answer_completeness(self, result: AdvisoryResult) -> float:
        """æ£€æŸ¥ç­”æ¡ˆå®Œæ•´æ€§"""
        completeness_score = 50.0  # åŸºç¡€åˆ†

        # æ£€æŸ¥ä¸»è¦ç­”æ¡ˆ
        if result.primary_answer and len(result.primary_answer) > 50:
            completeness_score += 20.0

        # æ£€æŸ¥è¯¦ç»†åˆ†æ
        if result.detailed_analysis:
            completeness_score += 15.0

        # æ£€æŸ¥æ¨èå»ºè®®
        if result.recommendations:
            completeness_score += 10.0

        # æ£€æŸ¥åç»­é—®é¢˜
        if result.follow_up_questions:
            completeness_score += 5.0

        return min(completeness_score, 100.0)

    async def _check_answer_relevance(self, result: AdvisoryResult,
                                    intent: UserIntent) -> float:
        """æ£€æŸ¥ç­”æ¡ˆç›¸å…³æ€§"""
        # ç®€åŒ–çš„ç›¸å…³æ€§æ£€æŸ¥
        relevance_score = 70.0  # åŸºç¡€åˆ†

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
        answer_text = result.primary_answer.lower()

        # æ ¹æ®æ„å›¾ç±»å‹æ£€æŸ¥ç›¸å…³æ€§
        if intent.primary_intent == IntentType.EQUIPMENT_RECOMMENDATION:
            if any(keyword in answer_text for keyword in ['æ¨è', 'è£…å¤‡', 'é€‰æ‹©', 'å“ç‰Œ', 'å‹å·']):
                relevance_score += 20.0
        elif intent.primary_intent == IntentType.STRATEGY_ADVICE:
            if any(keyword in answer_text for keyword in ['ç­–ç•¥', 'æŠ€å·§', 'æ–¹æ³•', 'å»ºè®®']):
                relevance_score += 20.0
        elif intent.primary_intent == IntentType.KNOWLEDGE_QUERY:
            if any(keyword in answer_text for keyword in ['æ ¹æ®', 'å› ä¸º', 'æ‰€ä»¥', 'ç‰¹ç‚¹']):
                relevance_score += 20.0

        return min(relevance_score, 100.0)

    def _check_professionalism(self, result: AdvisoryResult) -> float:
        """æ£€æŸ¥ä¸“ä¸šæ€§"""
        professionalism_score = 60.0  # åŸºç¡€åˆ†

        answer_text = result.primary_answer

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
        professional_terms = [
            'è°ƒæ€§', 'é±¼çº¿è½®', 'æ‹Ÿé¥µ', 'ç¢³çº¤ç»´', 'è½´æ‰¿', 'é½¿è½®æ¯”',
            'æ´»æ€§', 'è§…é£Ÿ', 'æ –æ¯åœ°', 'æ°´å±‚', 'æ³³å§¿'
        ]

        term_count = sum(1 for term in professional_terms if term in answer_text)
        if term_count >= 2:
            professionalism_score += 25.0
        elif term_count >= 1:
            professionalism_score += 15.0

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®æ”¯æ’‘
        if any(char.isdigit() for char in answer_text):
            professionalism_score += 10.0

        # æ£€æŸ¥ç»“æ„åŒ–ç¨‹åº¦
        if 'ï¼š' in answer_text or 'â€¢' in answer_text or '1.' in answer_text:
            professionalism_score += 5.0

        return min(professionalism_score, 100.0)

    def _check_readability(self, result: AdvisoryResult) -> float:
        """æ£€æŸ¥å¯è¯»æ€§"""
        answer_text = result.primary_answer

        # åŸºç¡€å¯è¯»æ€§è¯„åˆ†
        readability_score = 80.0

        # æ£€æŸ¥å¥å­é•¿åº¦
        sentences = answer_text.split('ã€‚')
        avg_sentence_length = sum(len(sentence) for sentence in sentences) / len(sentences) if sentences else 0

        if 10 <= avg_sentence_length <= 50:
            readability_score += 10.0
        elif avg_sentence_length > 80:
            readability_score -= 10.0

        # æ£€æŸ¥æ®µè½ç»“æ„
        paragraphs = answer_text.split('\n\n')
        if len(paragraphs) > 1:
            readability_score += 5.0

        # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡é•¿çš„æ®µè½
        for paragraph in paragraphs:
            if len(paragraph) > 300:
                readability_score -= 5.0
                break

        return max(0, min(readability_score, 100.0))

    def _create_error_result(self, error_message: str, original_query: str) -> AdvisoryResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return AdvisoryResult(
            advisory_id=self._generate_plan_id(),
            success=False,
            primary_answer=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{error_message}",
            detailed_analysis={'error': error_message, 'original_query': original_query},
            recommendations=[],
            follow_up_questions=["æ‚¨å¯ä»¥å°è¯•æ¢ä¸ªé—®æ³•ï¼Œæˆ–è€…æä¾›æ›´å¤šå…·ä½“ä¿¡æ¯ã€‚"],
            confidence_score=0.0,
            execution_time=0.0,
            service_contributions={}
        )

    # è¾…åŠ©æ–¹æ³•
    def _generate_cache_key(self, query: str, intent: UserIntent, context: AdvisoryContext) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib

        content = f"{query}:{intent.primary_intent.value}:{context.user_id or 'anonymous'}"
        return f"advisory:{hashlib.md5(content.encode()).hexdigest()}"

    def _generate_plan_id(self) -> str:
        """ç”Ÿæˆè®¡åˆ’ID"""
        import uuid
        return f"plan_{uuid.uuid4().hex[:8]}"

    def _generate_step_id(self) -> str:
        """ç”Ÿæˆæ­¥éª¤ID"""
        import uuid
        return f"step_{uuid.uuid4().hex[:8]}"

    def _identify_required_services(self, workflow_steps: List[WorkflowStep]) -> List[str]:
        """è¯†åˆ«éœ€è¦çš„æœåŠ¡"""
        services = set()
        for step in workflow_steps:
            services.update(step.required_services)
        return list(services)

    def _determine_execution_strategy(self, intent: UserIntent) -> str:
        """ç¡®å®šæ‰§è¡Œç­–ç•¥"""
        if intent.complexity == QueryComplexity.SIMPLE:
            return "sequential"
        elif intent.complexity == QueryComplexity.MODERATE:
            return "parallel_where_possible"
        else:
            return "adaptive"

    def _estimate_execution_time(self, workflow_steps: List[WorkflowStep],
                                complexity: QueryComplexity) -> float:
        """ä¼°ç®—æ‰§è¡Œæ—¶é—´"""
        base_time = len(workflow_steps) * 2.0  # æ¯æ­¥åŸºç¡€2ç§’

        complexity_multiplier = {
            QueryComplexity.SIMPLE: 1.0,
            QueryComplexity.MODERATE: 1.5,
            QueryComplexity.COMPLEX: 2.0,
            QueryComplexity.VERY_COMPLEX: 3.0
        }

        return base_time * complexity_multiplier[complexity]

    async def _adjust_step_for_context(self, step: WorkflowStep,
                                     intent: UserIntent,
                                     context: AdvisoryContext) -> WorkflowStep:
        """æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´æ­¥éª¤"""
        # æ ¹æ®ç”¨æˆ·å†å²è°ƒæ•´æœåŠ¡é€‰æ‹©
        if context.user_profile and 'preferred_services' in context.user_profile:
            preferred_services = context.user_profile['preferred_services']
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·åå¥½çš„æœåŠ¡
            for service in preferred_services:
                if service in step.required_services:
                    step.required_services.insert(0, step.required_services.pop(
                        step.required_services.index(service)
                    ))
                    break

        # æ ¹æ®ç¯å¢ƒä¿¡æ¯è°ƒæ•´å‚æ•°
        if context.environment_info:
            step.input_data.update(context.environment_info)

        return step

    def _build_scenario_query(self, scenario: Dict[str, Any]) -> str:
        """æ„å»ºåœºæ™¯æŸ¥è¯¢"""
        # ä»åœºæ™¯ä¿¡æ¯ä¸­æ„å»ºè‡ªç„¶è¯­è¨€æŸ¥è¯¢
        query_parts = []

        if 'location' in scenario:
            query_parts.append(f"åœ¨{scenario['location']}")

        if 'target_fish' in scenario:
            query_parts.append(f"é’“{scenario['target_fish']}")

        if 'season' in scenario:
            query_parts.append(f"{scenario['season']}å­£èŠ‚")

        if 'weather' in scenario:
            query_parts.append(f"{scenario['weather']}å¤©æ°”")

        if 'equipment' in scenario:
            query_parts.append(f"ä½¿ç”¨{scenario['equipment']}")

        return "ï¼Œ".join(query_parts) + "ï¼Œè¯·ç»™æˆ‘ä¸“ä¸šçš„å»ºè®®"

    def _enrich_context_with_scenario(self, context: AdvisoryContext,
                                    scenario: Dict[str, Any]) -> AdvisoryContext:
        """ç”¨åœºæ™¯ä¿¡æ¯ä¸°å¯Œä¸Šä¸‹æ–‡"""
        enriched_context = AdvisoryContext(
            user_id=context.user_id,
            conversation_history=context.conversation_history,
            user_profile=context.user_profile,
            current_session=context.current_session,
            environment_info={**context.environment_info, **scenario},
            temporal_context=context.temporal_context
        )

        return enriched_context

    async def _analyze_scenario_details(self, scenario: Dict[str, Any],
                                      service_contributions: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æåœºæ™¯è¯¦æƒ…"""
        return {
            'scenario_summary': f"åœ¨{scenario.get('location', 'æœªçŸ¥åœ°ç‚¹')}çš„{scenario.get('season', 'å½“å‰å­£èŠ‚')}é’“{scenario.get('target_fish', 'ç›®æ ‡é±¼ç§')}",
            'key_factors': self._identify_key_factors(scenario),
            'recommendation_basis': self._analyze_recommendation_basis(service_contributions),
            'risk_assessment': self._assess_scenario_risks(scenario)
        }

    def _identify_key_factors(self, scenario: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«å…³é”®å› ç´ """
        factors = []

        if 'weather' in scenario:
            factors.append(f"å¤©æ°”æ¡ä»¶ï¼š{scenario['weather']}")

        if 'target_fish' in scenario:
            factors.append(f"ç›®æ ‡é±¼ç§ï¼š{scenario['target_fish']}")

        if 'season' in scenario:
            factors.append(f"å­£èŠ‚å› ç´ ï¼š{scenario['season']}")

        if 'location' in scenario:
            factors.append(f"åœ°ç‚¹ç‰¹å¾ï¼š{scenario['location']}")

        return factors

    def _analyze_recommendation_basis(self, service_contributions: Dict[str, Any]) -> str:
        """åˆ†ææ¨èä¾æ®"""
        contributions = []

        for service, contribution in service_contributions.items():
            if contribution and isinstance(contribution, dict) and 'confidence' in contribution:
                contributions.append(f"{service}(ç½®ä¿¡åº¦:{contribution['confidence']:.1f})")

        return f"åŸºäº{', '.join(contributions)}çš„åˆ†æç»“æœ"

    def _assess_scenario_risks(self, scenario: Dict[str, Any]) -> List[str]:
        """è¯„ä¼°åœºæ™¯é£é™©"""
        risks = []

        if 'weather' in scenario:
            weather = scenario['weather'].lower()
            if 'é›¨' in weather or 'é£' in weather:
                risks.append("å¤©æ°”æ¡ä»¶å¯èƒ½å½±å“é’“é±¼æ•ˆæœ")

        if 'season' in scenario:
            season = scenario['season']
            if season in ['å†¬å­£', 'æ·±ç§‹']:
                risks.append("å­£èŠ‚æ€§é±¼æ´»æ€§è¾ƒä½")

        return risks

    def _build_solution_query(self, requirements: Dict[str, Any]) -> str:
        """æ„å»ºè§£å†³æ–¹æ¡ˆæŸ¥è¯¢"""
        query_parts = ["è¯·ä¸ºæˆ‘æä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ"]

        if 'experience_level' in requirements:
            query_parts.append(f"é€‚åˆ{requirements['experience_level']}æ°´å¹³")

        if 'budget' in requirements:
            query_parts.append(f"é¢„ç®—{requirements['budget']}å…ƒ")

        if 'primary_use' in requirements:
            query_parts.append(f"ä¸»è¦ç”¨äº{requirements['primary_use']}")

        if 'location' in requirements:
            query_parts.append(f"åœ¨{requirements['location']}ä½¿ç”¨")

        return "ï¼Œ".join(query_parts)

    async def _generate_complete_solution(self, requirements: Dict[str, Any],
                                        service_contributions: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´è§£å†³æ–¹æ¡ˆ"""
        return {
            'solution_overview': f"ä¸º{requirements.get('experience_level', 'é’“é±¼çˆ±å¥½è€…')}é‡èº«å®šåˆ¶çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ",
            'component_analysis': self._analyze_solution_components(service_contributions),
            'implementation_steps': self._generate_implementation_steps(requirements),
            'expected_outcomes': self._predict_outcomes(requirements, service_contributions),
            'budget_breakdown': self._analyze_budget_allocation(requirements, service_contributions)
        }

    def _analyze_solution_components(self, service_contributions: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè§£å†³æ–¹æ¡ˆç»„ä»¶"""
        components = {}

        if 'recommendation_engine' in service_contributions:
            components['equipment'] = "è£…å¤‡é…ç½®æ–¹æ¡ˆ"

        if 'strategy_service' in service_contributions:
            components['strategy'] = "é’“é±¼ç­–ç•¥å»ºè®®"

        if 'fish_knowledge_service' in service_contributions:
            components['knowledge'] = "ä¸“ä¸šçŸ¥è¯†æŒ‡å¯¼"

        return components

    def _generate_implementation_steps(self, requirements: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå®æ–½æ­¥éª¤"""
        steps = []

        steps.append("1. å‡†å¤‡åŸºç¡€è£…å¤‡å’Œé…ä»¶")
        steps.append("2. å­¦ä¹ åŸºæœ¬é’“é±¼æŠ€å·§å’Œå®‰å…¨çŸ¥è¯†")
        steps.append("3. é€‰æ‹©åˆé€‚çš„é’“ç‚¹å’Œæ—¶é—´")
        steps.append("4. å®è·µå’Œè°ƒæ•´é’“é±¼ç­–ç•¥")
        steps.append("5. æ ¹æ®ç»éªŒä¼˜åŒ–è£…å¤‡é…ç½®")

        return steps

    def _predict_outcomes(self, requirements: Dict[str, Any],
                         service_contributions: Dict[str, Any]) -> List[str]:
        """é¢„æµ‹é¢„æœŸæ•ˆæœ"""
        outcomes = []

        if requirements.get('experience_level') == 'beginner':
            outcomes.append("å¿«é€ŸæŒæ¡åŸºç¡€é’“é±¼æŠ€èƒ½")
            outcomes.append("å»ºç«‹æ­£ç¡®çš„é’“é±¼ä¹ æƒ¯")
        else:
            outcomes.append("æå‡é’“é±¼æ•ˆç‡å’ŒæˆåŠŸç‡")
            outcomes.append("æ‰©å±•é’“é±¼æŠ€èƒ½å’ŒçŸ¥è¯†")

        outcomes.append("è·å¾—ä¸“ä¸šçš„è£…å¤‡é…ç½®")
        outcomes.append("äº«å—é’“é±¼ä¹è¶£å¹¶å–å¾—è‰¯å¥½æ”¶è·")

        return outcomes

    def _analyze_budget_allocation(self, requirements: Dict[str, Any],
                                 service_contributions: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé¢„ç®—åˆ†é…"""
        total_budget = requirements.get('budget', 0)

        if total_budget > 0:
            # ç®€åŒ–çš„é¢„ç®—åˆ†é…åˆ†æ
            allocation = {
                'equipment': total_budget * 0.7,
                'accessories': total_budget * 0.2,
                'learning': total_budget * 0.1
            }
        else:
            allocation = {}

        return {
            'total_budget': total_budget,
            'allocation': allocation,
            'optimization_suggestions': self._generate_budget_suggestions(allocation)
        }

    def _generate_budget_suggestions(self, allocation: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆé¢„ç®—å»ºè®®"""
        suggestions = []

        if allocation:
            total = sum(allocation.values())
            if allocation.get('equipment', 0) / total < 0.6:
                suggestions.append("å»ºè®®å¢åŠ è£…å¤‡é¢„ç®—æ¯”é‡")
            if allocation.get('learning', 0) / total < 0.05:
                suggestions.append("å»ºè®®é¢„ç•™éƒ¨åˆ†é¢„ç®—ç”¨äºå­¦ä¹ æå‡")
        else:
            suggestions.append("å»ºè®®æ˜ç¡®é¢„ç®—èŒƒå›´ä»¥è·å¾—æ›´ç²¾ç¡®çš„å»ºè®®")

        return suggestions
```

## ğŸ”§ æœåŠ¡å±‚å®ç°

### å·¥ä½œæµç¼–æ’å™¨ (WorkflowOrchestrator)
```python
import asyncio
from concurrent.futures import TimeoutError

class WorkflowOrchestrator:
    """å·¥ä½œæµç¼–æ’å™¨"""

    def __init__(self, service_manager: 'ServiceManager'):
        self.service_manager = service_manager
        self.execution_engine = ExecutionEngine()
        self.step_monitor = StepMonitor()
        self.dependency_resolver = DependencyResolver()

    async def execute_workflow(self, plan: AdvisoryPlan,
                             context: AdvisoryContext) -> WorkflowExecution:
        """æ‰§è¡Œå·¥ä½œæµ"""
        execution_id = self._generate_execution_id()

        execution = WorkflowExecution(
            execution_id=execution_id,
            plan=plan,
            current_step=0,
            completed_steps=[],
            step_results={},
            execution_status='running',
            start_time=datetime.now()
        )

        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {execution_id}")

            # æ„å»ºæ‰§è¡Œå›¾
            execution_graph = await self._build_execution_graph(plan.workflow_steps)

            # æ‰§è¡Œå·¥ä½œæµ
            await self._execute_execution_graph(execution, execution_graph, context)

            # æ ‡è®°æ‰§è¡Œå®Œæˆ
            execution.execution_status = 'completed'
            execution.end_time = datetime.now()

            logger.info(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {execution_id}")

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            execution.execution_status = 'failed'
            execution.error_info = {
                'error': str(e),
                'failed_step': execution.current_step,
                'timestamp': datetime.now().isoformat()
            }
            execution.end_time = datetime.now()

        return execution

    async def _build_execution_graph(self, workflow_steps: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ„å»ºæ‰§è¡Œå›¾"""
        # æ„å»ºæ­¥éª¤ä¾èµ–å›¾
        step_graph = {}
        step_map = {}

        # åˆ›å»ºæ­¥éª¤å¯¹è±¡
        for step_data in workflow_steps:
            step = WorkflowStep(
                step_id=step_data.get('step_id', self._generate_step_id()),
                step_type=WorkflowStepType(step_data['type']),
                description=step_data['description'],
                required_services=step_data['services'],
                input_data=step_data.get('input_data', {}),
                expected_output=step_data['expected_output'],
                execution_order=step_data['order'],
                dependencies=step_data.get('dependencies', []),
                timeout=step_data.get('timeout', 30.0),
                retry_count=step_data.get('retry_count', 3)
            )
            step_map[step.step_id] = step
            step_graph[step.step_id] = {
                'step': step,
                'dependencies': step.dependencies,
                'dependents': []
            }

        # æ„å»ºåå‘ä¾èµ–å…³ç³»
        for step_id, step_info in step_graph.items():
            for dep_id in step_info['dependencies']:
                if dep_id in step_graph:
                    step_graph[dep_id]['dependents'].append(step_id)

        return step_graph

    async def _execute_execution_graph(self, execution: WorkflowExecution,
                                     execution_graph: Dict[str, Any],
                                     context: AdvisoryContext):
        """æ‰§è¡Œæ‰§è¡Œå›¾"""
        # æ‰¾åˆ°æ²¡æœ‰ä¾èµ–çš„èµ·å§‹æ­¥éª¤
        ready_steps = [
            step_id for step_id, step_info in execution_graph.items()
            if not step_info['dependencies']
        ]

        executed_steps = set()
        failed_steps = set()

        while ready_steps and not failed_steps:
            # æŒ‰æ‰§è¡Œé¡ºåºæ’åº
            ready_steps.sort(key=lambda x: execution_graph[x]['step'].execution_order)

            # å¹¶è¡Œæ‰§è¡Œå°±ç»ªçš„æ­¥éª¤
            current_batch = ready_steps.copy()
            ready_steps.clear()

            # æ‰§è¡Œå½“å‰æ‰¹æ¬¡
            tasks = []
            for step_id in current_batch:
                task = self._execute_step(
                    execution_graph[step_id]['step'],
                    execution,
                    context
                )
                tasks.append((step_id, task))

            # ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
            results = await asyncio.gather(
                *[task for _, task in tasks],
                return_exceptions=True
            )

            # å¤„ç†æ‰§è¡Œç»“æœ
            for (step_id, _), result in zip(tasks, results):
                if isinstance(result, Exception):
                    logger.error(f"æ­¥éª¤ {step_id} æ‰§è¡Œå¤±è´¥: {result}")
                    failed_steps.add(step_id)
                    execution.error_info = {
                        'error': str(result),
                        'failed_step': step_id,
                        'timestamp': datetime.now().isoformat()
                    }
                else:
                    executed_steps.add(step_id)
                    execution.step_results[step_id] = result
                    execution.completed_steps.append(step_id)

                    # æ£€æŸ¥ä¾èµ–æ­¤æ­¥éª¤çš„å…¶ä»–æ­¥éª¤æ˜¯å¦å¯ä»¥æ‰§è¡Œ
                    for dependent_id in execution_graph[step_id]['dependents']:
                        if dependent_id not in executed_steps and dependent_id not in failed_steps:
                            dependencies_met = all(
                                dep in executed_steps
                                for dep in execution_graph[dependent_id]['dependencies']
                            )
                            if dependencies_met:
                                ready_steps.append(dependent_id)

        if failed_steps:
            raise WorkflowExecutionError(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼Œå¤±è´¥çš„æ­¥éª¤: {failed_steps}")

    async def _execute_step(self, step: WorkflowStep,
                          execution: WorkflowExecution,
                          context: AdvisoryContext) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        execution.current_step = execution.plan.workflow_steps.index(
            next(s for s in execution.plan.workflow_steps if s.get('step_id') == step.step_id)
        ) + 1

        logger.info(f"æ‰§è¡Œæ­¥éª¤ {step.step_id}: {step.description}")

        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = self._prepare_step_input(step, execution, context)

        # æ‰§è¡Œæ­¥éª¤
        result = await self._execute_step_with_retry(step, input_data, context)

        # éªŒè¯è¾“å‡º
        self._validate_step_output(step, result)

        # è®°å½•æ‰§è¡Œæ—¶é—´
        self.step_monitor.record_step_execution(step.step_id, result)

        logger.info(f"æ­¥éª¤ {step.step_id} æ‰§è¡Œå®Œæˆ")
        return result

    def _prepare_step_input(self, step: WorkflowStep,
                           execution: WorkflowExecution,
                           context: AdvisoryContext) -> Dict[str, Any]:
        """å‡†å¤‡æ­¥éª¤è¾“å…¥æ•°æ®"""
        input_data = {
            **step.input_data,
            'context': context.__dict__,
            'execution_id': execution.execution_id,
            'previous_results': {
                dep_id: execution.step_results[dep_id]
                for dep_id in step.dependencies
                if dep_id in execution.step_results
            }
        }

        return input_data

    async def _execute_step_with_retry(self, step: WorkflowStep,
                                     input_data: Dict[str, Any],
                                     context: AdvisoryContext) -> Dict[str, Any]:
        """å¸¦é‡è¯•çš„æ­¥éª¤æ‰§è¡Œ"""
        last_exception = None

        for attempt in range(step.retry_count + 1):
            try:
                # è·å–æ‰€éœ€æœåŠ¡
                services = {
                    service_name: self.service_manager.get_service(service_name)
                    for service_name in step.required_services
                }

                # æ‰§è¡Œæ­¥éª¤
                result = await self.execution_engine.execute_step(
                    step.step_type, services, input_data
                )

                return result

            except Exception as e:
                last_exception = e
                logger.warning(f"æ­¥éª¤ {step.step_id} ç¬¬ {attempt + 1} æ¬¡æ‰§è¡Œå¤±è´¥: {e}")

                if attempt < step.retry_count:
                    # æŒ‡æ•°é€€é¿
                    await asyncio.sleep(2 ** attempt)
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    raise StepExecutionError(
                        f"æ­¥éª¤ {step.step_id} æ‰§è¡Œå¤±è´¥ï¼Œå·²é‡è¯• {step.retry_count} æ¬¡: {e}"
                    ) from e

        raise last_exception

    def _validate_step_output(self, step: WorkflowStep, result: Dict[str, Any]):
        """éªŒè¯æ­¥éª¤è¾“å‡º"""
        expected_keys = step.expected_output.keys()
        actual_keys = result.keys()

        missing_keys = expected_keys - actual_keys
        if missing_keys:
            logger.warning(f"æ­¥éª¤ {step.step_id} ç¼ºå°‘é¢„æœŸè¾“å‡º: {missing_keys}")

    def _generate_execution_id(self) -> str:
        """ç”Ÿæˆæ‰§è¡ŒID"""
        import uuid
        return f"exec_{uuid.uuid4().hex[:8]}"

    def _generate_step_id(self) -> str:
        """ç”Ÿæˆæ­¥éª¤ID"""
        import uuid
        return f"step_{uuid.uuid4().hex[:8]}"


class ExecutionEngine:
    """æ‰§è¡Œå¼•æ“"""

    async def execute_step(self, step_type: WorkflowStepType,
                         services: Dict[str, Any],
                         input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ­¥éª¤"""
        if step_type == WorkflowStepType.INTENT_ANALYSIS:
            return await self._execute_intent_analysis(services, input_data)
        elif step_type == WorkflowStepType.KNOWLEDGE_RETRIEVAL:
            return await self._execute_knowledge_retrieval(services, input_data)
        elif step_type == WorkflowStepType.DATA_ANALYSIS:
            return await self._execute_data_analysis(services, input_data)
        elif step_type == WorkflowStepType.SERVICE_COORDINATION:
            return await self._execute_service_coordination(services, input_data)
        elif step_type == WorkflowStepType.RESULT_SYNTHESIS:
            return await self._execute_result_synthesis(services, input_data)
        elif step_type == WorkflowStepType.QUALITY_CHECK:
            return await self._execute_quality_check(services, input_data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ­¥éª¤ç±»å‹: {step_type}")

    async def _execute_intent_analysis(self, services: Dict[str, Any],
                                     input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ„å›¾åˆ†æ"""
        intent_classifier = services.get('intent_classifier')

        if not intent_classifier:
            raise ValueError("ç¼ºå°‘æ„å›¾åˆ†ç±»å™¨æœåŠ¡")

        query = input_data.get('query', '')
        context = input_data.get('context', {})

        # æ‰§è¡Œæ„å›¾åˆ†æ
        intent = await intent_classifier.classify_intent(query, context)

        return {
            'intent_confirmed': True,
            'classified_intent': intent.__dict__,
            'confidence': intent.confidence,
            'complexity': intent.complexity.value
        }

    async def _execute_knowledge_retrieval(self, services: Dict[str, Any],
                                         input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        knowledge_data = {}

        # è°ƒç”¨å„ç§çŸ¥è¯†æœåŠ¡
        for service_name, service in services.items():
            if 'knowledge' in service_name.lower() or 'fish' in service_name.lower():
                try:
                    if hasattr(service, 'get_knowledge'):
                        service_result = await service.get_knowledge(input_data)
                        knowledge_data[service_name] = service_result
                except Exception as e:
                    logger.warning(f"çŸ¥è¯†æœåŠ¡ {service_name} è°ƒç”¨å¤±è´¥: {e}")

        return {
            'knowledge_data': knowledge_data,
            'total_sources': len(knowledge_data)
        }

    async def _execute_data_analysis(self, services: Dict[str, Any],
                                   input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åˆ†æ"""
        analysis_results = {}

        for service_name, service in services.items():
            try:
                if hasattr(service, 'analyze'):
                    analysis_result = await service.analyze(input_data)
                    analysis_results[service_name] = analysis_result
            except Exception as e:
                logger.warning(f"åˆ†ææœåŠ¡ {service_name} è°ƒç”¨å¤±è´¥: {e}")

        return {
            'analysis_results': analysis_results,
            'analysis_count': len(analysis_results)
        }

    async def _execute_service_coordination(self, services: Dict[str, Any],
                                          input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒæœåŠ¡åè°ƒ"""
        coordination_results = {}

        # åè°ƒå¤šä¸ªæœåŠ¡çš„æ‰§è¡Œ
        for service_name, service in services.items():
            try:
                if hasattr(service, 'process'):
                    result = await service.process(input_data)
                    coordination_results[service_name] = result
            except Exception as e:
                logger.warning(f"åè°ƒæœåŠ¡ {service_name} è°ƒç”¨å¤±è´¥: {e}")

        return {
            'coordination_results': coordination_results,
            'services_coordinated': len(coordination_results)
        }

    async def _execute_result_synthesis(self, services: Dict[str, Any],
                                      input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç»“æœåˆæˆ"""
        synthesizer = services.get('result_synthesizer')

        if not synthesizer:
            # ç®€å•çš„ç»“æœåˆæˆ
            return {
                'final_answer': self._simple_synthesis(input_data),
                'synthesis_method': 'simple'
            }

        try:
            synthesized_result = await synthesizer.synthesize(input_data)
            return {
                'final_answer': synthesized_result,
                'synthesis_method': 'advanced'
            }
        except Exception as e:
            logger.warning(f"é«˜çº§åˆæˆå¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆæˆ: {e}")
            return {
                'final_answer': self._simple_synthesis(input_data),
                'synthesis_method': 'fallback'
            }

    def _simple_synthesis(self, input_data: Dict[str, Any]) -> str:
        """ç®€å•ç»“æœåˆæˆ"""
        parts = []

        if 'previous_results' in input_data:
            for step_name, result in input_data['previous_results'].items():
                if isinstance(result, dict) and 'final_answer' in result:
                    parts.append(result['final_answer'])
                elif isinstance(result, str):
                    parts.append(result)

        return " ".join(parts) if parts else "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚"

    async def _execute_quality_check(self, services: Dict[str, Any],
                                    input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè´¨é‡æ£€æŸ¥"""
        quality_scores = {}

        for service_name, service in services.items():
            try:
                if hasattr(service, 'check_quality'):
                    score = await service.check_quality(input_data)
                    quality_scores[service_name] = score
            except Exception as e:
                logger.warning(f"è´¨é‡æ£€æŸ¥æœåŠ¡ {service_name} è°ƒç”¨å¤±è´¥: {e}")

        return {
            'quality_scores': quality_scores,
            'overall_quality': sum(quality_scores.values()) / len(quality_scores) if quality_scores else 0.0
        }


class StepMonitor:
    """æ­¥éª¤ç›‘æ§å™¨"""

    def __init__(self):
        self.execution_stats = {}

    def record_step_execution(self, step_id: str, result: Dict[str, Any]):
        """è®°å½•æ­¥éª¤æ‰§è¡Œ"""
        if step_id not in self.execution_stats:
            self.execution_stats[step_id] = {
                'execution_count': 0,
                'total_time': 0.0,
                'success_count': 0,
                'error_count': 0
            }

        stats = self.execution_stats[step_id]
        stats['execution_count'] += 1
        stats['success_count'] += 1

        if 'execution_time' in result:
            stats['total_time'] += result['execution_time']

    def get_step_stats(self, step_id: str) -> Dict[str, Any]:
        """è·å–æ­¥éª¤ç»Ÿè®¡"""
        return self.execution_stats.get(step_id, {})


class DependencyResolver:
    """ä¾èµ–è§£æå™¨"""

    def resolve_dependencies(self, workflow_steps: List[WorkflowStep]) -> List[WorkflowStep]:
        """è§£æä¾èµ–å…³ç³»å¹¶è¿”å›æ‰§è¡Œé¡ºåº"""
        # ç®€åŒ–çš„æ‹“æ‰‘æ’åº
        steps = workflow_steps.copy()
        ordered_steps = []

        while steps:
            # æ‰¾åˆ°æ²¡æœ‰æœªå®Œæˆä¾èµ–çš„æ­¥éª¤
            ready_steps = [
                step for step in steps
                if all(dep not in steps for dep in step.dependencies)
            ]

            if not ready_steps:
                raise ValueError("å‘ç°å¾ªç¯ä¾èµ–")

            # æŒ‰æ‰§è¡Œé¡ºåºæ’åº
            ready_steps.sort(key=lambda x: x.execution_order)

            # æ·»åŠ åˆ°ç»“æœä¸­
            ordered_steps.extend(ready_steps)

            # ä»å¾…å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
            for step in ready_steps:
                steps.remove(step)

        return ordered_steps


class WorkflowExecutionError(Exception):
    """å·¥ä½œæµæ‰§è¡Œå¼‚å¸¸"""
    pass


class StepExecutionError(Exception):
    """æ­¥éª¤æ‰§è¡Œå¼‚å¸¸"""
    pass
```

## ğŸ› ï¸ LangChainå·¥å…·é›†æˆ

### æ™ºèƒ½é¡¾é—®å·¥å…·å‡½æ•°
```python
from langchain_core.tools import tool
from typing import Dict, Any, List, Optional

@tool
def provide_comprehensive_fishing_advice(
    query: str,
    user_context: Optional[Dict[str, Any]] = None,
    location: Optional[str] = None,
    experience_level: Optional[str] = None,
    budget: Optional[float] = None
) -> Dict[str, Any]:
    """
    æä¾›ç»¼åˆçš„é’“é±¼å»ºè®®å’ŒæŒ‡å¯¼

    Args:
        query: ç”¨æˆ·çš„é—®é¢˜æˆ–éœ€æ±‚æè¿°
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        location: é’“é±¼åœ°ç‚¹ï¼ˆå¯é€‰ï¼‰
        experience_level: ç»éªŒæ°´å¹³ï¼ˆå¯é€‰ï¼‰
        budget: é¢„ç®—ï¼ˆå¯é€‰ï¼‰

    Returns:
        Dict: åŒ…å«ç»¼åˆå»ºè®®ã€è¯¦ç»†åˆ†æã€æ¨èæ–¹æ¡ˆç­‰
    """
    try:
        # æ„å»ºé¡¾é—®ä¸Šä¸‹æ–‡
        context = AdvisoryContext(
            user_id=user_context.get('user_id') if user_context else None,
            conversation_history=user_context.get('history', []) if user_context else [],
            user_profile=user_context.get('profile', {}) if user_context else {},
            current_session={},
            environment_info={
                'location': location,
                'experience_level': experience_level,
                'budget': budget
            } if any([location, experience_level, budget]) else {},
            temporal_context={
                'current_time': datetime.now().isoformat(),
                'season': _get_current_season()
            }
        )

        # è·å–æ™ºèƒ½é¡¾é—®æœåŠ¡
        service_container = get_service_container()
        advisor_service = service_container.get_service('intelligent_advisor')

        # æ‰§è¡Œç»¼åˆå»ºè®®
        result = advisor_service.provide_comprehensive_advice(query, context)

        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        return {
            "success": result.success,
            "primary_answer": result.primary_answer,
            "detailed_analysis": result.detailed_analysis,
            "recommendations": result.recommendations,
            "follow_up_questions": result.follow_up_questions,
            "confidence_score": f"{result.confidence_score:.1f}/100",
            "execution_time": f"{result.execution_time:.2f}s",
            "service_contributions": {
                service: contribution.get('confidence', 0.0)
                for service, contribution in result.service_contributions.items()
            }
        }

    except Exception as e:
        logger.error(f"ç»¼åˆå»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "å¾ˆæŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç»¼åˆå»ºè®®ï¼Œè¯·ç¨åé‡è¯•"
        }

@tool
def analyze_fishing_scenario(
    location: str,
    target_fish: List[str],
    season: Optional[str] = None,
    weather_condition: Optional[str] = None,
    equipment_available: Optional[List[Dict[str, str]]] = None,
    experience_level: Optional[str] = None
) -> Dict[str, Any]:
    """
    åˆ†æå…·ä½“çš„é’“é±¼åœºæ™¯å¹¶æä¾›ä¸“ä¸šå»ºè®®

    Args:
        location: é’“é±¼åœ°ç‚¹
        target_fish: ç›®æ ‡é±¼ç§åˆ—è¡¨
        season: å­£èŠ‚ï¼ˆå¯é€‰ï¼‰
        weather_condition: å¤©æ°”æ¡ä»¶ï¼ˆå¯é€‰ï¼‰
        equipment_available: ç°æœ‰è£…å¤‡ï¼ˆå¯é€‰ï¼‰
        experience_level: ç»éªŒæ°´å¹³ï¼ˆå¯é€‰ï¼‰

    Returns:
        Dict: åŒ…å«åœºæ™¯åˆ†æã€ç­–ç•¥å»ºè®®ã€è£…å¤‡æ¨èç­‰
    """
    try:
        # æ„å»ºåœºæ™¯ä¿¡æ¯
        scenario = {
            'location': location,
            'target_fish': target_fish,
            'season': season or _get_current_season(),
            'weather': weather_condition or "æœªçŸ¥",
            'equipment': equipment_available or [],
            'experience_level': experience_level or "intermediate"
        }

        # æ„å»ºä¸Šä¸‹æ–‡
        context = AdvisoryContext(
            user_id=None,
            conversation_history=[],
            user_profile={'experience_level': experience_level} if experience_level else {},
            current_session={},
            environment_info=scenario,
            temporal_context={
                'current_time': datetime.now().isoformat(),
                'season': season or _get_current_season()
            }
        )

        # è·å–æ™ºèƒ½é¡¾é—®æœåŠ¡
        service_container = get_service_container()
        advisor_service = service_container.get_service('intelligent_advisor')

        # æ‰§è¡Œåœºæ™¯åˆ†æ
        result = advisor_service.analyze_fishing_scenario(scenario, context)

        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        return {
            "success": result.success,
            "scenario_summary": result.detailed_analysis.get('scenario_analysis', {}).get('scenario_summary', ''),
            "key_factors": result.detailed_analysis.get('scenario_analysis', {}).get('key_factors', []),
            "recommendation_basis": result.detailed_analysis.get('scenario_analysis', {}).get('recommendation_basis', ''),
            "risk_assessment": result.detailed_analysis.get('scenario_analysis', {}).get('risk_assessment', []),
            "primary_advice": result.primary_answer,
            "detailed_recommendations": result.recommendations,
            "follow_up_suggestions": result.follow_up_questions,
            "confidence_score": f"{result.confidence_score:.1f}/100"
        }

    except Exception as e:
        logger.error(f"é’“é±¼åœºæ™¯åˆ†æå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "å¾ˆæŠ±æ­‰ï¼Œæ— æ³•åˆ†æé’“é±¼åœºæ™¯"
        }

@tool
def recommend_complete_fishing_solution(
    experience_level: str,
    budget: float,
    primary_use: str,
    location: Optional[str] = None,
    target_fish: Optional[List[str]] = None,
    special_requirements: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    æ¨èå®Œæ•´çš„é’“é±¼è§£å†³æ–¹æ¡ˆ

    Args:
        experience_level: ç»éªŒæ°´å¹³ (beginner/intermediate/advanced/professional)
        budget: æ€»é¢„ç®—
        primary_use: ä¸»è¦ç”¨é€” (è·¯äºš/å°é’“/æµ·é’“/æºªæµ/é»‘å‘)
        location: ä¸»è¦é’“é±¼åœ°ç‚¹ï¼ˆå¯é€‰ï¼‰
        target_fish: ç›®æ ‡é±¼ç§ï¼ˆå¯é€‰ï¼‰
        special_requirements: ç‰¹æ®Šéœ€æ±‚ï¼ˆå¯é€‰ï¼‰

    Returns:
        Dict: åŒ…å«å®Œæ•´è§£å†³æ–¹æ¡ˆã€è£…å¤‡é…ç½®ã€å®æ–½æ­¥éª¤ç­‰
    """
    try:
        # æ„å»ºéœ€æ±‚ä¿¡æ¯
        requirements = {
            'experience_level': experience_level,
            'budget': budget,
            'primary_use': primary_use,
            'location': location,
            'target_fish': target_fish or [],
            'special_requirements': special_requirements or []
        }

        # æ„å»ºä¸Šä¸‹æ–‡
        context = AdvisoryContext(
            user_id=None,
            conversation_history=[],
            user_profile={
                'experience_level': experience_level,
                'budget': budget,
                'primary_use': primary_use
            },
            current_session={},
            environment_info=requirements,
            temporal_context={
                'current_time': datetime.now().isoformat()
            }
        )

        # è·å–æ™ºèƒ½é¡¾é—®æœåŠ¡
        service_container = get_service_container()
        advisor_service = service_container.get_service('intelligent_advisor')

        # æ‰§è¡Œè§£å†³æ–¹æ¡ˆæ¨è
        result = advisor_service.recommend_complete_solution(requirements, context)

        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        solution_analysis = result.detailed_analysis.get('complete_solution', {})

        return {
            "success": result.success,
            "solution_overview": solution_analysis.get('solution_overview', ''),
            "component_analysis": solution_analysis.get('component_analysis', {}),
            "implementation_steps": solution_analysis.get('implementation_steps', []),
            "expected_outcomes": solution_analysis.get('expected_outcomes', []),
            "budget_breakdown": solution_analysis.get('budget_breakdown', {}),
            "primary_recommendation": result.primary_answer,
            "detailed_recommendations": result.recommendations,
            "equipment_configurations": _extract_equipment_configs(result.recommendations),
            "learning_resources": _extract_learning_resources(result.recommendations),
            "confidence_score": f"{result.confidence_score:.1f}/100"
        }

    except Exception as e:
        logger.error(f"å®Œæ•´è§£å†³æ–¹æ¡ˆæ¨èå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "å¾ˆæŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆå®Œæ•´è§£å†³æ–¹æ¡ˆ"
        }

# è¾…åŠ©å‡½æ•°
def _get_current_season() -> str:
    """è·å–å½“å‰å­£èŠ‚"""
    from datetime import datetime
    month = datetime.now().month

    if month in [12, 1, 2]:
        return "å†¬å­£"
    elif month in [3, 4, 5]:
        return "æ˜¥å­£"
    elif month in [6, 7, 8]:
        return "å¤å­£"
    else:
        return "ç§‹å­£"

def _extract_equipment_configs(recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æå–è£…å¤‡é…ç½®"""
    equipment_configs = []

    for recommendation in recommendations:
        if 'equipment' in recommendation or 'è£…å¤‡' in str(recommendation):
            equipment_configs.append(recommendation)

    return equipment_configs[:5]  # æœ€å¤šè¿”å›5ä¸ªè£…å¤‡é…ç½®

def _extract_learning_resources(recommendations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æå–å­¦ä¹ èµ„æº"""
    learning_resources = []

    for recommendation in recommendations:
        if any(keyword in str(recommendation).lower()
               for keyword in ['å­¦ä¹ ', 'æ•™ç¨‹', 'æŠ€å·§', 'æŒ‡å¯¼', 'è¯¾ç¨‹']):
            learning_resources.append(recommendation)

    return learning_resources[:3]  # æœ€å¤šè¿”å›3ä¸ªå­¦ä¹ èµ„æº

def get_service_container():
    """è·å–æœåŠ¡å®¹å™¨"""
    from shared.infrastructure.service_manager import get_service_manager
    return get_service_manager()
```

## ğŸ¯ å¼€å‘å®æ–½æŒ‡å—

### å¼€å‘ä¼˜å…ˆçº§å’Œé‡Œç¨‹ç¢‘

#### ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒé¡¾é—®å¼•æ“ï¼ˆ3å‘¨ï¼‰
**ç›®æ ‡**ï¼šå»ºç«‹åŸºç¡€çš„æ™ºèƒ½é¡¾é—®èƒ½åŠ›

**Week 1: æ„å›¾è¯†åˆ«å’Œåˆ†æ**
- [ ] å®ç°IntentClassifieræ„å›¾åˆ†ç±»å™¨
- [ ] å¼€å‘å¤åˆæ„å›¾å¤„ç†é€»è¾‘
- [ ] å»ºç«‹æŸ¥è¯¢å¤æ‚åº¦è¯„ä¼°æœºåˆ¶
- [ ] åˆ›å»ºå®ä½“è¯†åˆ«å’Œæå–åŠŸèƒ½

**Week 2: å·¥ä½œæµç¼–æ’ç³»ç»Ÿ**
- [ ] å®ç°WorkflowOrchestratorå·¥ä½œæµç¼–æ’å™¨
- [ ] å¼€å‘ExecutionEngineæ‰§è¡Œå¼•æ“
- [ ] å»ºç«‹ä¾èµ–è§£æå’Œæ‰§è¡Œå›¾æ„å»º
- [ ] å®ç°æ­¥éª¤ç›‘æ§å’Œé”™è¯¯å¤„ç†

**Week 3: ç»“æœåˆæˆå’Œè´¨é‡æ£€æŸ¥**
- [ ] å®ç°ResultSynthesizerç»“æœåˆæˆå™¨
- [ ] å¼€å‘å¤šæºä¿¡æ¯æ•´åˆç®—æ³•
- [ ] å»ºç«‹è´¨é‡æ£€æŸ¥å’Œè¯„åˆ†æœºåˆ¶
- [ ] åˆ›å»ºç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–

#### ç¬¬äºŒé˜¶æ®µï¼šè·¨ç³»ç»Ÿé›†æˆï¼ˆ2å‘¨ï¼‰
**ç›®æ ‡**ï¼šå®ç°ä¸å„å­ç³»ç»Ÿçš„æ·±åº¦é›†æˆ

**Week 4: ç³»ç»Ÿåè°ƒæœºåˆ¶**
- [ ] å®ç°ä¸é±¼ç±»çŸ¥è¯†ç³»ç»Ÿçš„é›†æˆ
- [ ] å¼€å‘ä¸è£…å¤‡æ¨èç³»ç»Ÿçš„åè°ƒ
- [ ] å»ºç«‹ä¸è£…å¤‡å¯¹æ¯”ç³»ç»Ÿçš„è”åŠ¨
- [ ] åˆ›å»ºæœåŠ¡é—´æ•°æ®ä¼ é€’æœºåˆ¶

**Week 5: æ™ºèƒ½å·¥ä½œæµä¼˜åŒ–**
- [ ] ä¼˜åŒ–å·¥ä½œæµæ‰§è¡Œæ•ˆç‡
- [ ] å®ç°å¹¶è¡Œæ‰§è¡Œå’Œå¼‚æ­¥å¤„ç†
- [ ] å»ºç«‹è‡ªé€‚åº”å·¥ä½œæµè°ƒæ•´
- [ ] å¼€å‘æ‰§è¡Œç›‘æ§å’Œè¯Šæ–­

#### ç¬¬ä¸‰é˜¶æ®µï¼šå·¥å…·é›†æˆå’Œä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰
**ç›®æ ‡**ï¼šå®ŒæˆLangChainå·¥å…·é›†æˆå’Œç³»ç»Ÿä¼˜åŒ–

**Week 6: å·¥å…·é›†æˆå’Œæµ‹è¯•**
- [ ] å¼€å‘LangChainå·¥å…·å‡½æ•°
- [ ] å®ç°ç«¯åˆ°ç«¯çš„å·¥ä½œæµæµ‹è¯•
- [ ] ä¼˜åŒ–æ€§èƒ½å’Œå“åº”æ—¶é—´
- [ ] åˆ›å»ºæ–‡æ¡£å’Œéƒ¨ç½²æŒ‡å—

### æŠ€æœ¯å®æ–½è¦ç‚¹

#### 1. æ„å›¾è¯†åˆ«å’Œåˆ†ç±»
- **å¤šçº§æ„å›¾åˆ†ç±»**: æ”¯æŒä¸»è¦æ„å›¾å’Œæ¬¡è¦æ„å›¾çš„è¯†åˆ«
- **ä¸Šä¸‹æ–‡ç†è§£**: åŸºäºå¯¹è¯å†å²å’Œç”¨æˆ·ç”»åƒçš„æ„å›¾ç†è§£
- **å¤æ‚åº¦è¯„ä¼°**: è¯„ä¼°æŸ¥è¯¢çš„å¤æ‚åº¦å’Œæ‰€éœ€èµ„æº
- **åŠ¨æ€è°ƒæ•´**: æ ¹æ®æ‰§è¡Œç»“æœåŠ¨æ€è°ƒæ•´æ„å›¾è¯†åˆ«

#### 2. å·¥ä½œæµç¼–æ’
- **ä¾èµ–ç®¡ç†**: æ™ºèƒ½è§£ææ­¥éª¤é—´çš„ä¾èµ–å…³ç³»
- **å¹¶è¡Œæ‰§è¡Œ**: æ”¯æŒæ— ä¾èµ–æ­¥éª¤çš„å¹¶è¡Œæ‰§è¡Œ
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **æ€§èƒ½ç›‘æ§**: å®æ—¶ç›‘æ§å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€å’Œæ€§èƒ½

#### 3. ç»“æœåˆæˆ
- **å¤šæºæ•´åˆ**: æ•´åˆæ¥è‡ªä¸åŒæœåŠ¡çš„ä¿¡æ¯
- **è´¨é‡ä¿è¯**: ç¡®ä¿åˆæˆç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- **ä¸ªæ€§åŒ–é€‚é…**: æ ¹æ®ç”¨æˆ·ç‰¹å¾è°ƒæ•´ç»“æœå‘ˆç°
- **å¯è§£é‡Šæ€§**: æä¾›ç»“æœçš„å¯è§£é‡Šæ€§å’Œæ¥æºè¿½æº¯

#### 4. ç³»ç»Ÿé›†æˆ
- **æœåŠ¡å‘ç°**: è‡ªåŠ¨å‘ç°å’Œè°ƒç”¨ç›¸å…³æœåŠ¡
- **æ•°æ®è½¬æ¢**: å¤„ç†ä¸åŒæœåŠ¡é—´çš„æ•°æ®æ ¼å¼è½¬æ¢
- **ç¼“å­˜ç­–ç•¥**: æ™ºèƒ½ç¼“å­˜å¸¸ç”¨æŸ¥è¯¢ç»“æœ
- **è´Ÿè½½å‡è¡¡**: åˆç†åˆ†é…ç³»ç»Ÿè´Ÿè½½

### æµ‹è¯•ç­–ç•¥

#### å•å…ƒæµ‹è¯•
```python
import pytest
from unittest.mock import Mock, AsyncMock

class TestIntelligentAdvisorService:
    """æ™ºèƒ½é¡¾é—®æœåŠ¡æµ‹è¯•"""

    @pytest.fixture
    def advisor_service(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„é¡¾é—®æœåŠ¡"""
        mock_intent_classifier = AsyncMock(spec=IntentClassifier)
        mock_workflow_orchestrator = AsyncMock(spec=WorkflowOrchestrator)
        mock_knowledge_integrator = Mock(spec=KnowledgeIntegrator)
        mock_result_synthesizer = AsyncMock(spec=ResultSynthesizer)
        mock_service_manager = Mock(spec=ServiceManager)

        return IntelligentAdvisorService(
            mock_intent_classifier,
            mock_workflow_orchestrator,
            mock_knowledge_integrator,
            mock_result_synthesizer,
            mock_service_manager
        )

    @pytest.mark.asyncio
    async def test_provide_comprehensive_advice_simple(self, advisor_service):
        """æµ‹è¯•ç®€å•æŸ¥è¯¢çš„ç»¼åˆå»ºè®®"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        query = "æ¨èä¸€æ¬¾å…¥é—¨çº§çš„è·¯äºšç«¿"
        context = AdvisoryContext(
            user_id="test_user",
            conversation_history=[],
            user_profile={'experience_level': 'beginner'},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        # è®¾ç½®mockè¿”å›å€¼
        mock_intent = UserIntent(
            primary_intent=IntentType.EQUIPMENT_RECOMMENDATION,
            secondary_intents=[],
            entities={'equipment_type': 'fishing_rod', 'level': 'beginner'},
            confidence=0.9,
            complexity=QueryComplexity.SIMPLE,
            context_requirements=[]
        )

        advisor_service.intent_classifier.classify_intent.return_value = mock_intent

        mock_plan = AdvisoryPlan(
            advisory_id="test_plan",
            intent=mock_intent,
            workflow_steps=[],
            required_services=[],
            execution_strategy="sequential",
            estimated_time=5.0
        )

        advisor_service._generate_advisory_plan = AsyncMock(return_value=mock_plan)

        mock_execution = WorkflowExecution(
            execution_id="test_exec",
            plan=mock_plan,
            current_step=0,
            completed_steps=[],
            step_results={},
            execution_status="completed",
            start_time=datetime.now(),
            end_time=datetime.now()
        )

        advisor_service.workflow_orchestrator.execute_workflow = AsyncMock(return_value=mock_execution)

        mock_result = AdvisoryResult(
            advisory_id="test_result",
            success=True,
            primary_answer="æ¨èæ‚¨é€‰æ‹©XXå“ç‰Œçš„å…¥é—¨çº§è·¯äºšç«¿",
            detailed_analysis={},
            recommendations=[],
            follow_up_questions=[],
            confidence_score=85.0,
            execution_time=2.5,
            service_contributions={}
        )

        advisor_service.result_synthesizer.synthesize_result = AsyncMock(return_value=mock_result)

        # æ‰§è¡Œæµ‹è¯•
        result = await advisor_service.provide_comprehensive_advice(query, context)

        # éªŒè¯ç»“æœ
        assert result.success is True
        assert result.primary_answer == "æ¨èæ‚¨é€‰æ‹©XXå“ç‰Œçš„å…¥é—¨çº§è·¯äºšç«¿"
        assert result.confidence_score == 85.0
        assert result.execution_time == 2.5

        # éªŒè¯è°ƒç”¨
        advisor_service.intent_classifier.classify_intent.assert_called_once_with(query, context)
        advisor_service.workflow_orchestrator.execute_workflow.assert_called_once()

    @pytest.mark.asyncio
    async def test_analyze_fishing_scenario(self, advisor_service):
        """æµ‹è¯•é’“é±¼åœºæ™¯åˆ†æ"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        scenario = {
            'location': 'æ­å·',
            'target_fish': ['é²ˆé±¼'],
            'season': 'æ˜¥å­£',
            'weather': 'æ™´å¤©'
        }

        context = AdvisoryContext(
            user_id="test_user",
            conversation_history=[],
            user_profile={},
            current_session={},
            environment_info=scenario,
            temporal_context={}
        )

        # æ¨¡æ‹Ÿç»¼åˆå»ºè®®çš„ç»“æœ
        mock_result = AdvisoryResult(
            advisory_id="scenario_result",
            success=True,
            primary_answer="æ ¹æ®æ­å·æ˜¥å­£é’“é²ˆé±¼çš„åœºæ™¯åˆ†æ...",
            detailed_analysis={
                'scenario_analysis': {
                    'scenario_summary': 'æ­å·æ˜¥å­£é’“é²ˆé±¼çš„ç»¼åˆåˆ†æ',
                    'key_factors': ['å¤©æ°”æ¡ä»¶è‰¯å¥½', 'é²ˆé±¼æ´»æ€§è¾ƒé«˜'],
                    'recommendation_basis': 'åŸºäºå¤šç³»ç»Ÿåˆ†æç»“æœ',
                    'risk_assessment': ['é£åŠ›è¾ƒå°ï¼Œé€‚åˆä½œé’“']
                }
            },
            recommendations=[],
            follow_up_questions=[],
            confidence_score=90.0,
            execution_time=3.0,
            service_contributions={}
        )

        advisor_service.provide_comprehensive_advice = AsyncMock(return_value=mock_result)

        # æ‰§è¡Œæµ‹è¯•
        result = await advisor_service.analyze_fishing_scenario(scenario, context)

        # éªŒè¯ç»“æœ
        assert result.success is True
        assert 'scenario_analysis' in result.detailed_analysis
        assert result.detailed_analysis['scenario_analysis']['scenario_summary'] == 'æ­å·æ˜¥å­£é’“é²ˆé±¼çš„ç»¼åˆåˆ†æ'
        assert len(result.detailed_analysis['scenario_analysis']['key_factors']) == 2

class TestWorkflowOrchestrator:
    """å·¥ä½œæµç¼–æ’å™¨æµ‹è¯•"""

    @pytest.fixture
    def orchestrator(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„å·¥ä½œæµç¼–æ’å™¨"""
        mock_service_manager = Mock(spec=ServiceManager)
        return WorkflowOrchestrator(mock_service_manager)

    @pytest.mark.asyncio
    async def test_execute_simple_workflow(self, orchestrator):
        """æµ‹è¯•ç®€å•å·¥ä½œæµæ‰§è¡Œ"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        plan = AdvisoryPlan(
            advisory_id="test_plan",
            intent=UserIntent(
                primary_intent=IntentType.KNOWLEDGE_QUERY,
                secondary_intents=[],
                entities={},
                confidence=0.9,
                complexity=QueryComplexity.SIMPLE,
                context_requirements=[]
            ),
            workflow_steps=[
                {
                    'step_id': 'step_1',
                    'type': 'intent_analysis',
                    'description': 'åˆ†ææ„å›¾',
                    'services': ['intent_classifier'],
                    'expected_output': {'intent_confirmed': True},
                    'order': 1,
                    'dependencies': []
                },
                {
                    'step_id': 'step_2',
                    'type': 'knowledge_retrieval',
                    'description': 'æ£€ç´¢çŸ¥è¯†',
                    'services': ['knowledge_service'],
                    'expected_output': {'knowledge_data': []},
                    'order': 2,
                    'dependencies': ['step_1']
                }
            ],
            required_services=['intent_classifier', 'knowledge_service'],
            execution_strategy="sequential",
            estimated_time=5.0
        )

        context = AdvisoryContext(
            user_id="test_user",
            conversation_history=[],
            user_profile={},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        # æ‰§è¡Œå·¥ä½œæµ
        execution = await orchestrator.execute_workflow(plan, context)

        # éªŒè¯ç»“æœ
        assert execution.execution_id is not None
        assert execution.execution_status == 'completed'
        assert execution.start_time is not None
        assert execution.end_time is not None
        assert len(execution.completed_steps) == 2
        assert execution.step_results is not None

    @pytest.mark.asyncio
    async def test_execute_workflow_with_parallel_steps(self, orchestrator):
        """æµ‹è¯•å¹¶è¡Œæ­¥éª¤æ‰§è¡Œ"""
        # å‡†å¤‡åŒ…å«å¹¶è¡Œæ­¥éª¤çš„å·¥ä½œæµ
        plan = AdvisoryPlan(
            advisory_id="parallel_plan",
            intent=UserIntent(
                primary_intent=IntentType.STRATEGY_ADVICE,
                secondary_intents=[],
                entities={},
                confidence=0.9,
                complexity=QueryComplexity.MODERATE,
                context_requirements=[]
            ),
            workflow_steps=[
                {
                    'step_id': 'step_1',
                    'type': 'intent_analysis',
                    'description': 'åˆ†ææ„å›¾',
                    'services': ['intent_classifier'],
                    'expected_output': {'intent_confirmed': True},
                    'order': 1,
                    'dependencies': []
                },
                {
                    'step_id': 'step_2a',
                    'type': 'knowledge_retrieval',
                    'description': 'è·å–çŸ¥è¯†',
                    'services': ['knowledge_service'],
                    'expected_output': {'knowledge_data': []},
                    'order': 2,
                    'dependencies': ['step_1']
                },
                {
                    'step_id': 'step_2b',
                    'type': 'data_analysis',
                    'description': 'åˆ†ææ•°æ®',
                    'services': ['analysis_service'],
                    'expected_output': {'analysis_result': {}},
                    'order': 2,
                    'dependencies': ['step_1']
                },
                {
                    'step_id': 'step_3',
                    'type': 'result_synthesis',
                    'description': 'åˆæˆç»“æœ',
                    'services': ['synthesizer'],
                    'expected_output': {'final_answer': ''},
                    'order': 3,
                    'dependencies': ['step_2a', 'step_2b']
                }
            ],
            required_services=['intent_classifier', 'knowledge_service', 'analysis_service', 'synthesizer'],
            execution_strategy="parallel_where_possible",
            estimated_time=8.0
        )

        context = AdvisoryContext(
            user_id="test_user",
            conversation_history=[],
            user_profile={},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        # æ‰§è¡Œå·¥ä½œæµ
        execution = await orchestrator.execute_workflow(plan, context)

        # éªŒè¯ç»“æœ
        assert execution.execution_status == 'completed'
        assert len(execution.completed_steps) == 4
        assert 'step_2a' in execution.completed_steps
        assert 'step_2b' in execution.completed_steps
        assert 'step_3' in execution.completed_steps
```

#### é›†æˆæµ‹è¯•
```python
class TestIntelligentAdvisorIntegration:
    """æ™ºèƒ½é¡¾é—®ç³»ç»Ÿé›†æˆæµ‹è¯•"""

    @pytest.fixture
    def integrated_system(self):
        """åˆ›å»ºé›†æˆæµ‹è¯•ç³»ç»Ÿ"""
        # åˆå§‹åŒ–çœŸå®çš„æœåŠ¡å®ä¾‹
        service_container = create_test_service_container()

        # åˆ›å»ºæ™ºèƒ½é¡¾é—®æœåŠ¡
        intent_classifier = IntentClassifier()
        workflow_orchestrator = WorkflowOrchestrator(service_container)
        knowledge_integrator = KnowledgeIntegrator(service_container)
        result_synthesizer = ResultSynthesizer()

        advisor_service = IntelligentAdvisorService(
            intent_classifier,
            workflow_orchestrator,
            knowledge_integrator,
            result_synthesizer,
            service_container
        )

        return advisor_service

    @pytest.mark.asyncio
    async def test_complete_advisory_workflow(self, integrated_system):
        """æµ‹è¯•å®Œæ•´çš„é¡¾é—®å·¥ä½œæµ"""
        # å‡†å¤‡æµ‹è¯•æŸ¥è¯¢
        query = "æˆ‘æ˜¯æ–°æ‰‹ï¼Œé¢„ç®—2000å…ƒï¼Œæƒ³å­¦è·¯äºšé’“é²ˆé±¼ï¼Œåœ¨æ­å·æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ"

        context = AdvisoryContext(
            user_id="integration_test_user",
            conversation_history=[
                {"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘æƒ³å­¦é’“é±¼"},
                {"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘å¾ˆä¹æ„å¸®åŠ©ä½ å­¦ä¹ é’“é±¼"}
            ],
            user_profile={
                'experience_level': 'beginner',
                'budget': 2000,
                'location': 'æ­å·'
            },
            current_session={},
            environment_info={
                'location': 'æ­å·',
                'season': 'æ˜¥å­£',
                'weather': 'æ™´å¤©'
            },
            temporal_context={
                'current_time': datetime.now().isoformat()
            }
        )

        # æ‰§è¡Œç»¼åˆå»ºè®®
        result = await integrated_system.provide_comprehensive_advice(query, context)

        # éªŒè¯ç»“æœ
        assert result.success is True
        assert len(result.primary_answer) > 50  # ç­”æ¡ˆåº”è¯¥æœ‰è¶³å¤Ÿçš„å†…å®¹
        assert result.confidence_score > 60  # ç½®ä¿¡åº¦åº”è¯¥åˆç†
        assert result.execution_time < 30  # æ‰§è¡Œæ—¶é—´åº”è¯¥åˆç†

        # éªŒè¯è¯¦ç»†åˆ†æ
        assert 'detailed_analysis' in result.__dict__

        # éªŒè¯æ¨èå»ºè®®
        if result.recommendations:
            assert isinstance(result.recommendations, list)

        # éªŒè¯åç»­é—®é¢˜
        if result.follow_up_questions:
            assert isinstance(result.follow_up_questions, list)
            assert len(result.follow_up_questions) > 0

    @pytest.mark.asyncio
    async def test_multi_intent_query(self, integrated_system):
        """æµ‹è¯•å¤šæ„å›¾æŸ¥è¯¢"""
        query = "æˆ‘æƒ³äº†è§£é²ˆé±¼çš„ä¹ æ€§ï¼ŒåŒæ—¶æ¨èä¸€äº›é€‚åˆæ–°æ‰‹çš„è·¯äºšè£…å¤‡ï¼Œé¢„ç®—1500å…ƒ"

        context = AdvisoryContext(
            user_id="multi_intent_test",
            conversation_history=[],
            user_profile={'experience_level': 'beginner'},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        # æ‰§è¡ŒæŸ¥è¯¢
        result = await integrated_system.provide_comprehensive_advice(query, context)

        # éªŒè¯ç»“æœ
        assert result.success is True

        # éªŒè¯ç­”æ¡ˆåŒ…å«å¤šä¸ªæ–¹é¢çš„å†…å®¹
        answer_text = result.primary_answer.lower()
        has_knowledge = any(keyword in answer_text for keyword in ['ä¹ æ€§', 'ä¹ æƒ¯', 'è¡Œä¸º', 'ç‰¹ç‚¹'])
        has_recommendation = any(keyword in answer_text for keyword in ['æ¨è', 'å»ºè®®', 'é€‰æ‹©', 'è£…å¤‡'])

        assert has_knowledge or has_recommendation, "ç­”æ¡ˆåº”è¯¥åŒ…å«çŸ¥è¯†æˆ–æ¨èå†…å®¹"

    @pytest.mark.asyncio
    async def test_context_aware_advice(self, integrated_system):
        """æµ‹è¯•ä¸Šä¸‹æ–‡æ„ŸçŸ¥å»ºè®®"""
        # ç¬¬ä¸€æ¬¡æŸ¥è¯¢
        query1 = "æ¨èä¸€æ¬¾å…¥é—¨è·¯äºšç«¿"
        context1 = AdvisoryContext(
            user_id="context_test_user",
            conversation_history=[],
            user_profile={'experience_level': 'beginner'},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        result1 = await integrated_system.provide_comprehensive_advice(query1, context1)

        # ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆæœ‰ä¸Šä¸‹æ–‡ï¼‰
        query2 = "é‚£é±¼è½®å‘¢ï¼Ÿ"
        context2 = AdvisoryContext(
            user_id="context_test_user",
            conversation_history=[
                {"role": "user", "content": query1},
                {"role": "assistant", "content": result1.primary_answer}
            ],
            user_profile={'experience_level': 'beginner'},
            current_session={},
            environment_info={},
            temporal_context={}
        )

        result2 = await integrated_system.provide_comprehensive_advice(query2, context2)

        # éªŒè¯ç»“æœ
        assert result2.success is True

        # éªŒè¯ç¬¬äºŒæ¬¡çš„ç­”æ¡ˆè€ƒè™‘äº†ä¸Šä¸‹æ–‡ï¼ˆåº”è¯¥æåˆ°ä¸é±¼ç«¿çš„æ­é…ï¼‰
        answer2_text = result2.primary_answer.lower()
        has_context_reference = any(keyword in answer2_text for keyword in ['æ­é…', 'é…åˆ', 'å¯¹åº”', 'åŒ¹é…'])

        # è¿™ä¸ªæ–­è¨€å¯èƒ½ä¼šå¤±è´¥ï¼Œå› ä¸ºä¸Šä¸‹æ–‡æ„ŸçŸ¥åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å¼€å‘
        # assert has_context_reference, "ç­”æ¡ˆåº”è¯¥è€ƒè™‘ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡"
```

### éƒ¨ç½²å’Œè¿ç»´

#### 1. æ€§èƒ½ä¼˜åŒ–
- **å¼‚æ­¥å¤„ç†**: å……åˆ†åˆ©ç”¨å¼‚æ­¥æ‰§è¡Œæå‡å¹¶å‘èƒ½åŠ›
- **ç¼“å­˜ç­–ç•¥**: å®ç°å¤šçº§ç¼“å­˜æå‡å“åº”é€Ÿåº¦
- **è¿æ¥æ± **: ä¼˜åŒ–æ•°æ®åº“å’ŒæœåŠ¡è¿æ¥ç®¡ç†
- **è´Ÿè½½å‡è¡¡**: æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²å’Œè´Ÿè½½åˆ†é…

#### 2. ç›‘æ§å’Œè¯Šæ–­
- **å·¥ä½œæµç›‘æ§**: å®æ—¶ç›‘æ§å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€
- **æ€§èƒ½æŒ‡æ ‡**: ç›‘æ§å“åº”æ—¶é—´ã€æˆåŠŸç‡ç­‰å…³é”®æŒ‡æ ‡
- **é”™è¯¯è¿½è¸ª**: å®Œå–„çš„é”™è¯¯æ—¥å¿—å’Œè¿½è¸ªæœºåˆ¶
- **èµ„æºç›‘æ§**: ç›‘æ§CPUã€å†…å­˜ã€ç½‘ç»œç­‰èµ„æºä½¿ç”¨

#### 3. æ‰©å±•æ€§è®¾è®¡
- **æ¨¡å—åŒ–æ¶æ„**: æ”¯æŒæ–°åŠŸèƒ½æ¨¡å—çš„å¿«é€Ÿé›†æˆ
- **æ’ä»¶æœºåˆ¶**: æ”¯æŒç¬¬ä¸‰æ–¹æœåŠ¡çš„æ’ä»¶å¼æ¥å…¥
- **é…ç½®ç®¡ç†**: çµæ´»çš„é…ç½®ç®¡ç†å’Œçƒ­æ›´æ–°
- **ç‰ˆæœ¬ç®¡ç†**: æ”¯æŒæœåŠ¡çš„å¹³æ»‘å‡çº§å’Œå›æ»š

---

## ğŸ“ å¼€å‘æ€»ç»“

æ™ºèƒ½é¡¾é—®ç³»ç»Ÿæ˜¯æ™ºèƒ½é’“é±¼ç”Ÿæ€ç³»ç»Ÿçš„æ ¸å¿ƒå¤§è„‘ï¼Œé€šè¿‡æ™ºèƒ½å·¥ä½œæµç¼–æ’å’Œè·¨ç³»ç»ŸååŒåˆ†æï¼Œä¸ºç”¨æˆ·æä¾›ä¸€ç«™å¼ã€ä¸“ä¸šåŒ–ã€ä¸ªæ€§åŒ–çš„é’“é±¼æŒ‡å¯¼æœåŠ¡ã€‚è¯¥ç³»ç»Ÿå®ç°äº†ä»å•ä¸€åŠŸèƒ½åˆ°ç»¼åˆæœåŠ¡çš„æ™ºèƒ½åŒ–å‡çº§ï¼Œæ˜¯æ•´ä¸ªç”Ÿæ€ç³»ç»Ÿçš„ä»·å€¼æ‰€åœ¨ã€‚

### æ ¸å¿ƒèƒ½åŠ›
- **æ™ºèƒ½æ„å›¾è¯†åˆ«**: å‡†ç¡®ç†è§£ç”¨æˆ·éœ€æ±‚å’ŒæŸ¥è¯¢æ„å›¾
- **å·¥ä½œæµç¼–æ’**: æ™ºèƒ½åè°ƒå¤šä¸ªå­ç³»ç»ŸååŒå·¥ä½œ
- **è·¨ç³»ç»Ÿæ•´åˆ**: æ·±åº¦æ•´åˆé±¼ç±»çŸ¥è¯†ã€è£…å¤‡æ¨èã€è£…å¤‡å¯¹æ¯”ç­‰èƒ½åŠ›
- **ä¸ªæ€§åŒ–æœåŠ¡**: åŸºäºç”¨æˆ·ç”»åƒå’Œä¸Šä¸‹æ–‡çš„ä¸ªæ€§åŒ–å»ºè®®

### æŠ€æœ¯ç‰¹è‰²
- **å¼‚æ­¥å·¥ä½œæµ**: æ”¯æŒå¹¶è¡Œæ‰§è¡Œå’Œå¤æ‚ä¾èµ–ç®¡ç†
- **æ™ºèƒ½åˆæˆ**: å¤šæºä¿¡æ¯çš„æ™ºèƒ½æ•´åˆå’Œè´¨é‡ä¿è¯
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**: åŸºäºå¯¹è¯å†å²çš„æ™ºèƒ½ä¸Šä¸‹æ–‡ç†è§£
- **LangChainé›†æˆ**: æ— ç¼é›†æˆåˆ°æ™ºèƒ½ä½“å¯¹è¯ç³»ç»Ÿ

è¯¥ç³»ç»Ÿä¸ºé’“é±¼çˆ±å¥½è€…æä¾›ä¸“å®¶çº§çš„ç»¼åˆæŒ‡å¯¼æœåŠ¡ï¼Œé€šè¿‡æ™ºèƒ½åŒ–çš„åˆ†æå’Œå»ºè®®ï¼Œæ˜¾è‘—æå‡ç”¨æˆ·çš„é’“é±¼ä½“éªŒå’ŒæˆåŠŸç‡ã€‚ä½œä¸ºæ•´ä¸ªç”Ÿæ€ç³»ç»Ÿçš„å…¥å£å’Œå¤§è„‘ï¼Œæ™ºèƒ½é¡¾é—®ç³»ç»Ÿå……åˆ†ä½“ç°äº†ç³»ç»Ÿçš„æ•´ä½“ä»·å€¼å’Œæ™ºèƒ½åŒ–æ°´å¹³ã€‚