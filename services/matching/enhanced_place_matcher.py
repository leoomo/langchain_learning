#!/usr/bin/env python3
"""
å¢å¼ºçš„åœ°ååŒ¹é…ç³»ç»Ÿ
æ”¯æŒå…¨å›½3000+å¿çº§è¡Œæ”¿åŒºçš„æ™ºèƒ½åŒ¹é…
åŒ…å«äº”çº§åŒºåˆ’åŒ¹é…ã€æ¨¡ç³ŠåŒ¹é…ã€æ‹¼éŸ³åŒ¹é…ç­‰é«˜çº§åŠŸèƒ½
"""

import sqlite3
import re
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set, Any
from difflib import SequenceMatcher
import unicodedata

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EnhancedPlaceMatcher:
    """å¢å¼ºçš„åœ°ååŒ¹é…å™¨"""

    def __init__(self, db_path: str = "data/admin_divisions.db"):
        self.db_path = db_path
        self.conn: Optional[sqlite3.Connection] = None
        self.cursor: Optional[sqlite3.Cursor] = None

        # åœ°åŒºç±»å‹æ˜ å°„
        self.level_names = {
            1: ["çœ", "è‡ªæ²»åŒº", "ç›´è¾–å¸‚", "ç‰¹åˆ«è¡Œæ”¿åŒº"],
            2: ["å¸‚", "åœ°åŒº", "è‡ªæ²»å·", "ç›Ÿ"],
            3: ["å¿", "åŒº", "å¸‚", "è‡ªæ²»å¿", "æ——", "è‡ªæ²»æ——", "æ—åŒº", "ç‰¹åŒº"],
            4: ["é•‡", "ä¹¡", "è¡—é“", "è‹æœ¨", "æ°‘æ—ä¹¡", "æ°‘æ—è‹æœ¨"],
            5: ["æ‘", "ç¤¾åŒº", "å±…å§”ä¼š", "å˜æŸ¥", "ç®¡å§”ä¼š"]
        }

        # å¸¸è§åˆ«åæ˜ å°„
        self.alias_map = self._build_alias_map()

        # åœ°åŒºåç¼€æ¨¡å¼
        self.suffix_patterns = [
            r'çœ$', r'è‡ªæ²»åŒº$', r'ç›´è¾–å¸‚$', r'ç‰¹åˆ«è¡Œæ”¿åŒº$',
            r'å¸‚$', r'åœ°åŒº$', r'è‡ªæ²»å·$', r'ç›Ÿ$',
            r'å¿$', r'åŒº$', r'å¸‚$', r'è‡ªæ²»å¿$', r'æ——$', r'è‡ªæ²»æ——$', r'æ—åŒº$', r'ç‰¹åŒº$',
            r'é•‡$', r'ä¹¡$', r'è¡—é“$', r'è‹æœ¨$', r'æ°‘æ—ä¹¡$', r'æ°‘æ—è‹æœ¨$',
            r'æ‘$', r'ç¤¾åŒº$', r'å±…å§”ä¼š$', r'å˜æŸ¥$', r'ç®¡å§”ä¼š$'
        ]

    def _build_alias_map(self) -> Dict[str, str]:
        """æ„å»ºå¸¸è§åœ°åŒºåˆ«åæ˜ å°„"""
        return {
            # åŒ—äº¬
            "äº¬": "åŒ—äº¬å¸‚", "ç‡•äº¬": "åŒ—äº¬å¸‚", "åŒ—å¹³": "åŒ—äº¬å¸‚", "é¦–éƒ½": "åŒ—äº¬å¸‚",
            # ä¸Šæµ·
            "æ²ª": "ä¸Šæµ·å¸‚", "ç”³": "ä¸Šæµ·å¸‚", "é­”éƒ½": "ä¸Šæµ·å¸‚",
            # å¤©æ´¥
            "æ´¥": "å¤©æ´¥å¸‚", "æ´¥é—¨": "å¤©æ´¥å¸‚",
            # é‡åº†
            "æ¸": "é‡åº†å¸‚", "å·´": "é‡åº†å¸‚", "å±±åŸ": "é‡åº†å¸‚",
            # å¹¿ä¸œ
            "ç²¤": "å¹¿ä¸œçœ", "ç¾ŠåŸ": "å¹¿å·å¸‚", "èŠ±åŸ": "å¹¿å·å¸‚", "ç©—": "å¹¿å·å¸‚",
            "é¹åŸ": "æ·±åœ³å¸‚", "æ·±": "æ·±åœ³å¸‚", "ç æµ·": "ç æµ·å¸‚", "ä½›å±±": "ä½›å±±å¸‚",
            # æ±Ÿè‹
            "è‹": "æ±Ÿè‹çœ", "å®": "å—äº¬å¸‚", "é‡‘é™µ": "å—äº¬å¸‚", "å»ºåº·": "å—äº¬å¸‚",
            "è‹": "è‹å·å¸‚", "å§‘è‹": "è‹å·å¸‚", "å¹³æ±Ÿ": "è‹å·å¸‚", "é”¡": "æ— é”¡å¸‚",
            "å¸¸": "å¸¸å·å¸‚", "é¾™åŸ": "å¸¸å·å¸‚", "é€š": "å—é€šå¸‚", "åŒ—ä¸Šæµ·": "å—é€šå¸‚",
            # æµ™æ±Ÿ
            "æµ™": "æµ™æ±Ÿçœ", "æ­": "æ­å·å¸‚", "æ­¦æ—": "æ­å·å¸‚", "é’±å¡˜": "æ­å·å¸‚",
            "ç”¬": "å®æ³¢å¸‚", "é¹¿åŸ": "æ¸©å·å¸‚", "ç¦¾åŸ": "å˜‰å…´å¸‚", "æ¹–åŸ": "æ¹–å·å¸‚",
            "è¶Šå·": "ç»å…´å¸‚", "å©ºå·": "é‡‘åå¸‚", "å°å·": "å°å·å¸‚",
            # å››å·
            "å·": "å››å·çœ", "èœ€": "å››å·çœ", "è“‰": "æˆéƒ½å¸‚", "é”¦åŸ": "æˆéƒ½å¸‚", "å¤©åºœ": "æˆéƒ½å¸‚",
            # é™•è¥¿
            "é™•": "é™•è¥¿çœ", "ç§¦": "é™•è¥¿çœ", "é•¿å®‰": "è¥¿å®‰å¸‚", "é•äº¬": "è¥¿å®‰å¸‚", "è¥¿äº¬": "è¥¿å®‰å¸‚",
            # å±±ä¸œ
            "é²": "å±±ä¸œçœ", "é½é²": "å±±ä¸œçœ", "æ³‰åŸ": "æµå—å¸‚", "é½å·": "æµå—å¸‚", "å†ä¸‹": "æµå—å¸‚",
            "å²›åŸ": "é’å²›å¸‚", "ç´å²›": "é’å²›å¸‚", "èƒ¶æ¾³": "é’å²›å¸‚",
            # æ²³å—
            "è±«": "æ²³å—çœ", "ä¸­åŸ": "æ²³å—çœ", "å•†éƒ½": "éƒ‘å·å¸‚", "ç»¿åŸ": "éƒ‘å·å¸‚",
            # æ¹–åŒ—
            "é„‚": "æ¹–åŒ—çœ", "æ¥š": "æ¹–åŒ—çœ", "æ±ŸåŸ": "æ­¦æ±‰å¸‚", "æ±Ÿå¤": "æ­¦æ±‰å¸‚",
            # æ¹–å—
            "æ¹˜": "æ¹–å—çœ", "æ½‡æ¹˜": "æ¹–å—çœ", "æ˜ŸåŸ": "é•¿æ²™å¸‚", "é•¿æ²™": "é•¿æ²™å¸‚", "æ½­å·": "é•¿æ²™å¸‚",
            # å…¶ä»–é‡è¦åŸå¸‚
            "ç››äº¬": "æ²ˆé˜³å¸‚", "å¥‰å¤©": "æ²ˆé˜³å¸‚", "æ²ˆ": "æ²ˆé˜³å¸‚",
            "æ»¨åŸ": "å¤§è¿å¸‚", "æ˜Ÿæµ·": "å¤§è¿å¸‚", "è¿": "å¤§è¿å¸‚",
            "æ¦•åŸ": "ç¦å·å¸‚", "å·¦æµ·": "ç¦å·å¸‚", "ä¸‰å±±": "ç¦å·å¸‚",
            "é¹­å²›": "å¦é—¨å¸‚", "å¦": "å¦é—¨å¸‚", "é—¨": "å¦é—¨å¸‚",
            "åºå·": "åˆè‚¥å¸‚", "åˆæ·": "åˆè‚¥å¸‚", "çš–": "åˆè‚¥å¸‚",
            "æ´ªéƒ½": "å—æ˜Œå¸‚", "å—æ˜Œ": "å—æ˜Œå¸‚", "èµ£": "å—æ˜Œå¸‚",
            "æ—åŸ": "è´µé˜³å¸‚", "ç­‘åŸ": "è´µé˜³å¸‚", "é‡‘é˜³": "è´µé˜³å¸‚",
            "æ˜¥åŸ": "æ˜†æ˜å¸‚", "æ˜†": "æ˜†æ˜å¸‚", "æ»‡": "æ˜†æ˜å¸‚",
            "æ—¥å…‰åŸ": "æ‹‰è¨å¸‚", "é€»äº›": "æ‹‰è¨å¸‚",
            "é‡‘åŸ": "å…°å·å¸‚",
            "å¤éƒ½": "è¥¿å®å¸‚",
            "å‡¤åŸ": "é“¶å·å¸‚", "å¡ä¸Šæ±Ÿå—": "é“¶å·å¸‚",
            "ä¹Œå¸‚": "ä¹Œé²æœ¨é½å¸‚", "è¿ªåŒ–": "ä¹Œé²æœ¨é½å¸‚",
        }

    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        self.cursor = self.conn.cursor()
        logger.info(f"å·²è¿æ¥åˆ°æ•°æ®åº“: {self.db_path}")

    def _ensure_connection(self) -> sqlite3.Cursor:
        """ç¡®ä¿æ•°æ®åº“è¿æ¥å¯ç”¨"""
        if self.cursor is None:
            self.connect()
        return self.cursor  # type: ignore

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def normalize_text(self, text: str) -> str:
        """æ ‡å‡†åŒ–æ–‡æœ¬"""
        if not text:
            return ""

        # è½¬æ¢ä¸ºç®€ä½“
        text = unicodedata.normalize('NFKC', text)

        # å»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        text = re.sub(r'\s+', '', text)
        text = re.sub(r'[^\w\u4e00-\u9fff]', '', text)

        return text.strip()

    def extract_region_name(self, query: str) -> str:
        """ä»æŸ¥è¯¢ä¸­æå–åœ°åŒºåç§°"""
        if not query:
            return ""

        # æ ‡å‡†åŒ–æŸ¥è¯¢
        query = self.normalize_text(query)

        # ç§»é™¤å¸¸è§çš„åœ°åŒºåç¼€
        for pattern in self.suffix_patterns:
            query = re.sub(pattern, '', query)

        return query

    def exact_match(self, name: str) -> Optional[Dict]:
        """ç²¾ç¡®åŒ¹é…"""
        normalized_name = self.normalize_text(name)

        # ç›´æ¥åŒ¹é…
        cursor = self._ensure_connection()
        cursor.execute("""
            SELECT code, name, level, province, city, district, street, longitude, latitude
            FROM regions
            WHERE name = ? OR pinyin = ?
            LIMIT 1
        """, (name, normalized_name.lower()))

        result = cursor.fetchone()
        if result:
            return self._format_result(result)

        return None

    def alias_match(self, name: str) -> Optional[Dict]:
        """åˆ«ååŒ¹é…"""
        normalized_name = self.normalize_text(name)

        # æ£€æŸ¥åˆ«åæ˜ å°„
        if normalized_name in self.alias_map:
            alias_name = self.alias_map[normalized_name]
            return self.exact_match(alias_name)

        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„åˆ«å
        cursor = self._ensure_connection()
        cursor.execute("""
            SELECT code, name, level, province, city, district, street, longitude, latitude
            FROM regions
            WHERE aliases LIKE ?
            LIMIT 1
        """, (f'%{name}%',))

        result = cursor.fetchone()
        if result:
            return self._format_result(result)

        return None

    def fuzzy_match(self, name: str, threshold: float = 0.7) -> Optional[Dict]:
        """æ¨¡ç³ŠåŒ¹é…"""
        normalized_name = self.normalize_text(name)

        if len(normalized_name) < 2:
            return None

        # è·å–æ‰€æœ‰å€™é€‰åœ°åŒº
        cursor = self._ensure_connection()
        cursor.execute("""
            SELECT code, name, level, province, city, district, street, longitude, latitude
            FROM regions
            WHERE LENGTH(name) >= ?
            ORDER BY level, LENGTH(name)
            LIMIT 100
        """, (len(normalized_name),))

        candidates = cursor.fetchall()
        best_match = None
        best_score = 0

        for candidate in candidates:
            candidate_name = candidate[1]

            # è®¡ç®—ç›¸ä¼¼åº¦
            score1 = SequenceMatcher(None, normalized_name, candidate_name).ratio()

            # è®¡ç®—åŒ…å«ç›¸ä¼¼åº¦
            score2 = 0
            if normalized_name in candidate_name or candidate_name in normalized_name:
                score2 = 0.8

            # ç»¼åˆè¯„åˆ†
            total_score = max(score1, score2)

            # çº§åˆ«æƒé‡ï¼ˆçœçº§ > å¸‚çº§ > å¿çº§ï¼‰
            level_weight = {1: 1.2, 2: 1.1, 3: 1.0, 4: 0.9, 5: 0.8}
            total_score *= level_weight.get(candidate[2], 1.0)

            if total_score > best_score and total_score >= threshold:
                best_score = total_score
                best_match = candidate

        if best_match:
            return self._format_result(best_match)

        return None

    def hierarchical_match(self, name: str, context: Optional[Dict] = None) -> Optional[Dict]:
        """å±‚çº§åŒ¹é…"""
        normalized_name = self.normalize_text(name)

        if context:
            # åœ¨ç‰¹å®šä¸Šä¸‹æ–‡ä¸­æœç´¢
            province = context.get('province')
            city = context.get('city')
            district = context.get('district')

            conditions = []
            params = [normalized_name]

            if province:
                conditions.append("province = ?")
                params.append(province)
            if city:
                conditions.append("city = ?")
                params.append(city)
            if district:
                conditions.append("district = ?")
                params.append(district)

            where_clause = " AND ".join(conditions) if conditions else "1=1"

            cursor = self._ensure_connection()
            cursor.execute(f"""
                SELECT code, name, level, province, city, district, street, longitude, latitude
                FROM regions
                WHERE (name LIKE ? OR pinyin LIKE ?) AND {where_clause}
                ORDER BY level DESC
                LIMIT 1
            """, [f'%{normalized_name}%', f'%{normalized_name.lower()}%'] + params)

            result = cursor.fetchone()
            if result:
                return self._format_result(result)

        return None

    def contains_match(self, name: str) -> Optional[Dict]:
        """åŒ…å«åŒ¹é…"""
        normalized_name = self.normalize_text(name)

        if len(normalized_name) < 2:
            return None

        cursor = self._ensure_connection()
        cursor.execute("""
            SELECT code, name, level, province, city, district, street, longitude, latitude
            FROM regions
            WHERE name LIKE ? OR pinyin LIKE ?
            ORDER BY level DESC, LENGTH(name)
            LIMIT 10
        """, (f'%{normalized_name}%', f'%{normalized_name.lower()}%'))

        results = cursor.fetchall()

        # é€‰æ‹©æœ€åŒ¹é…çš„ç»“æœ
        for result in results:
            result_name = result[1]
            if normalized_name in result_name or result_name in normalized_name:
                return self._format_result(result)

        # å¦‚æœæ²¡æœ‰ç›´æ¥åŒ…å«ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªç»“æœ
        if results:
            return self._format_result(results[0])

        return None

    def _format_result(self, result: Tuple) -> Dict:
        """æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœ"""
        return {
            'code': result[0],
            'name': result[1],
            'level': result[2],
            'level_name': self._get_level_name(result[2]),
            'province': result[3],
            'city': result[4],
            'district': result[5],
            'street': result[6],
            'longitude': float(result[7]) if result[7] is not None else None,
            'latitude': float(result[8]) if result[8] is not None else None,
            'full_address': self._build_full_address(result)
        }

    def _get_level_name(self, level: int) -> str:
        """è·å–çº§åˆ«åç§°"""
        level_names = {
            1: "çœçº§",
            2: "åœ°çº§",
            3: "å¿çº§",
            4: "ä¹¡é•‡çº§",
            5: "æ‘çº§"
        }
        return level_names.get(level, f"çº§åˆ«{level}")

    def _build_full_address(self, result: Tuple) -> str:
        """æ„å»ºå®Œæ•´åœ°å€"""
        parts = []
        if result[3]:  # province
            parts.append(result[3])
        if result[4] and result[4] != result[3]:  # city
            parts.append(result[4])
        if result[5] and result[5] != result[4]:  # district
            parts.append(result[5])
        if result[6] and result[6] != result[5]:  # street
            parts.append(result[6])

        return "".join(parts)

    def match_place(self, query: str, context: Optional[Dict] = None) -> Optional[Dict]:
        """ä¸»åŒ¹é…æ–¹æ³•"""
        if not query:
            return None

        logger.debug(f"å¼€å§‹åŒ¹é…åœ°å: {query}")

        # 1. ç²¾ç¡®åŒ¹é…
        result = self.exact_match(query)
        if result:
            logger.debug(f"ç²¾ç¡®åŒ¹é…æˆåŠŸ: {result['name']}")
            return result

        # 2. åˆ«ååŒ¹é…
        result = self.alias_match(query)
        if result:
            logger.debug(f"åˆ«ååŒ¹é…æˆåŠŸ: {result['name']}")
            return result

        # 3. å±‚çº§åŒ¹é…
        result = self.hierarchical_match(query, context)
        if result:
            logger.debug(f"å±‚çº§åŒ¹é…æˆåŠŸ: {result['name']}")
            return result

        # 4. åŒ…å«åŒ¹é…
        result = self.contains_match(query)
        if result:
            logger.debug(f"åŒ…å«åŒ¹é…æˆåŠŸ: {result['name']}")
            return result

        # 5. æ¨¡ç³ŠåŒ¹é…
        result = self.fuzzy_match(query)
        if result:
            logger.debug(f"æ¨¡ç³ŠåŒ¹é…æˆåŠŸ: {result['name']}")
            return result

        logger.debug(f"åŒ¹é…å¤±è´¥: {query}")
        return None

    def batch_match(self, queries: List[str]) -> List[Optional[Dict]]:
        """æ‰¹é‡åŒ¹é…"""
        results = []
        for query in queries:
            result = self.match_place(query)
            results.append(result)
        return results

    def get_statistics(self) -> Dict:
        """è·å–åŒ¹é…å™¨ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}

        # æ€»æ•°ç»Ÿè®¡
        cursor = self._ensure_connection()
        cursor.execute("SELECT COUNT(*) FROM regions")
        stats['total_regions'] = cursor.fetchone()[0]

        # æŒ‰çº§åˆ«ç»Ÿè®¡
        cursor = self._ensure_connection()
        cursor.execute("SELECT level, COUNT(*) FROM regions GROUP BY level ORDER BY level")
        stats['by_level'] = dict(cursor.fetchall())

        # æœ‰åæ ‡ç»Ÿè®¡
        cursor = self._ensure_connection()
        cursor.execute("SELECT COUNT(*) FROM regions WHERE longitude IS NOT NULL AND latitude IS NOT NULL")
        stats['with_coordinates'] = cursor.fetchone()[0]

        # åˆ«åç»Ÿè®¡
        stats['alias_count'] = len(self.alias_map)

        return stats

    def test_matching_performance(self, test_queries: List[str]) -> Dict:
        """æµ‹è¯•åŒ¹é…æ€§èƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•åŒ¹é…æ€§èƒ½...")

        results = {
            'total_queries': len(test_queries),
            'successful_matches': 0,
            'failed_matches': 0,
            'match_details': []
        }

        import time
        start_time = time.time()

        for query in test_queries:
            match_start = time.time()
            result = self.match_place(query)
            match_time = time.time() - match_start

            if result:
                results['successful_matches'] += 1
                results['match_details'].append({
                    'query': query,
                    'matched': result['name'],
                    'level': result['level_name'],
                    'time': match_time,
                    'success': True
                })
            else:
                results['failed_matches'] += 1
                results['match_details'].append({
                    'query': query,
                    'matched': None,
                    'level': None,
                    'time': match_time,
                    'success': False
                })

        total_time = time.time() - start_time
        results['total_time'] = total_time
        results['average_time'] = total_time / len(test_queries)
        results['success_rate'] = results['successful_matches'] / len(test_queries)

        logger.info(f"åŒ¹é…æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        logger.info(f"   æ€»æŸ¥è¯¢æ•°: {results['total_queries']}")
        logger.info(f"   æˆåŠŸåŒ¹é…: {results['successful_matches']}")
        logger.info(f"   åŒ¹é…å¤±è´¥: {results['failed_matches']}")
        logger.info(f"   æˆåŠŸç‡: {results['success_rate']*100:.1f}%")
        logger.info(f"   å¹³å‡è€—æ—¶: {results['average_time']*1000:.2f}ms")

        return results

def main():
    """ä¸»å‡½æ•° - æµ‹è¯•å¢å¼ºåŒ¹é…å™¨"""
    matcher = EnhancedPlaceMatcher()

    try:
        matcher.connect()

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = matcher.get_statistics()
        logger.info("ğŸ“Š å¢å¼ºåœ°ååŒ¹é…å™¨ç»Ÿè®¡:")
        logger.info(f"   æ€»åœ°åŒºæ•°: {stats['total_regions']}")
        logger.info(f"   æŒ‰çº§åˆ«åˆ†å¸ƒ: {stats['by_level']}")
        logger.info(f"   æœ‰åæ ‡åœ°åŒº: {stats['with_coordinates']}")
        logger.info(f"   åˆ«åæ˜ å°„æ•°: {stats['alias_count']}")

        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "æˆéƒ½", "è¥¿å®‰",
            "æœé˜³åŒº", "å¤©æ²³åŒº", "æµ·æ·€åŒº", "ç¦ç”°åŒº",
            "ä¸­å±±è·¯", "äººæ°‘è·¯", "è§£æ”¾è·¯", "å»ºè®¾è·¯",
            "æ²™æ²³é•‡", "å¤ªå¹³é•‡", "æ–°å¡˜é•‡", "æ°¸å®é•‡",
            "äº¬", "æ²ª", "ç²¤", "è‹", "æµ™", "å·", "é²",
            "ç‡•äº¬", "é‡‘é™µ", "é¹åŸ", "è“‰åŸ", "é•¿å®‰"
        ]

        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        performance_results = matcher.test_matching_performance(test_queries)

        # æ˜¾ç¤ºéƒ¨åˆ†åŒ¹é…ç»“æœ
        logger.info("\nğŸ” åŒ¹é…ç»“æœç¤ºä¾‹:")
        for detail in performance_results['match_details'][:10]:
            if detail['success']:
                logger.info(f"   {detail['query']} -> {detail['matched']} ({detail['level']})")
            else:
                logger.info(f"   {detail['query']} -> æœªåŒ¹é…")

    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise
    finally:
        matcher.close()

if __name__ == "__main__":
    main()