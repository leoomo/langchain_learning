#!/usr/bin/env python3
"""
æ‰©å±•è¡Œæ”¿åŒºåˆ’æ•°æ®åº“ä¸ºæ”¯æŒå…¨å›½4.5ä¸‡ä¹¡é•‡çº§æ•°æ®
åŒ…å«äº”çº§åŒºåˆ’ï¼šçœ->å¸‚->å¿->ä¹¡->æ‘
"""

import sqlite3
import json
import requests
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import time
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NationalRegionDatabase:
    """å…¨å›½è¡Œæ”¿åŒºåˆ’æ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self, db_path: str = "data/admin_divisions.db"):
        self.db_path = db_path
        self.ensure_data_directory()
        self.conn = None
        self.cursor = None

    def ensure_data_directory(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)

    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = sqlite3.connect(self.db_path)
        self.cursor = self.conn.cursor()
        logger.info(f"å·²è¿æ¥åˆ°æ•°æ®åº“: {self.db_path}")

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def create_extended_schema(self):
        """åˆ›å»ºæ‰©å±•çš„æ•°æ®åº“æ¶æ„æ”¯æŒäº”çº§åŒºåˆ’"""
        logger.info("å¼€å§‹åˆ›å»ºæ‰©å±•æ•°æ®åº“æ¶æ„...")

        # å¤‡ä»½ç°æœ‰æ•°æ®
        self.backup_existing_data()

        # é‡åˆ›å»ºè¡¨ç»“æ„
        self.cursor.execute('DROP TABLE IF EXISTS regions')

        create_table_sql = '''
        CREATE TABLE regions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            code TEXT UNIQUE NOT NULL,          -- 12ä½åŒºåˆ’ä»£ç 
            name TEXT NOT NULL,                -- æ ‡å‡†åç§°
            parent_code TEXT,                   -- ä¸Šçº§åŒºåˆ’ä»£ç 
            level INTEGER NOT NULL,             -- è¡Œæ”¿çº§åˆ«(1çœ 2å¸‚ 3å¿ 4ä¹¡ 5æ‘)
            longitude REAL,                     -- ç»åº¦
            latitude REAL,                      -- çº¬åº¦
            pinyin TEXT,                        -- æ‹¼éŸ³
            aliases TEXT,                       -- åˆ«å(JSONæ ¼å¼)
            province TEXT,                      -- çœä»½
            city TEXT,                          -- å¸‚
            district TEXT,                      -- åŒºå¿
            street TEXT,                        -- ä¹¡é•‡/è¡—é“
            community TEXT,                    -- æ‘/ç¤¾åŒº
            urban_rural_type TEXT,             -- åŸä¹¡åˆ†ç±»ä»£ç 
            data_source TEXT,                   -- æ•°æ®æ¥æº
            data_quality REAL DEFAULT 1.0,     -- æ•°æ®è´¨é‡è¯„åˆ†(0-1)
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        '''

        self.cursor.execute(create_table_sql)

        # åˆ›å»ºä¼˜åŒ–ç´¢å¼•
        indexes = [
            'CREATE INDEX idx_regions_name ON regions(name)',
            'CREATE INDEX idx_regions_pinyin ON regions(pinyin)',
            'CREATE INDEX idx_regions_parent_code ON regions(parent_code)',
            'CREATE INDEX idx_regions_level ON regions(level)',
            'CREATE INDEX idx_regions_coordinates ON regions(longitude, latitude)',
            'CREATE INDEX idx_regions_hierarchy ON regions(province, city, district, street)',
            'CREATE INDEX idx_regions_code ON regions(code)',
            'CREATE INDEX idx_regions_data_source ON regions(data_source)'
        ]

        for index_sql in indexes:
            self.cursor.execute(index_sql)

        # æ¢å¤ç°æœ‰æ•°æ®
        self.restore_existing_data()

        self.conn.commit()
        logger.info("âœ… æ‰©å±•æ•°æ®åº“æ¶æ„åˆ›å»ºå®Œæˆ")

    def backup_existing_data(self):
        """å¤‡ä»½ç°æœ‰æ•°æ®"""
        try:
            self.cursor.execute('SELECT * FROM regions')
            existing_data = self.cursor.fetchall()

            if existing_data:
                # è·å–åˆ—å
                self.cursor.execute('PRAGMA table_info(regions)')
                columns = [col[1] for col in self.cursor.fetchall()]

                # ä¿å­˜åˆ°ä¸´æ—¶è¡¨
                backup_df = pd.DataFrame(existing_data, columns=columns)
                backup_df.to_csv('data/backup_regions.csv', index=False, encoding='utf-8')
                logger.info(f"å·²å¤‡ä»½ {len(existing_data)} æ¡ç°æœ‰æ•°æ®")

                return backup_df
        except Exception as e:
            logger.warning(f"å¤‡ä»½æ•°æ®æ—¶å‡ºç°é—®é¢˜: {e}")

        return None

    def restore_existing_data(self):
        """æ¢å¤ç°æœ‰æ•°æ®åˆ°æ–°è¡¨ç»“æ„"""
        backup_file = Path('data/backup_regions.csv')
        if backup_file.exists():
            try:
                backup_df = pd.read_csv(backup_file, encoding='utf-8')

                # è½¬æ¢æ•°æ®åˆ°æ–°ç»“æ„
                for _, row in backup_df.iterrows():
                    # å¡«å……æ–°çš„å±‚çº§å­—æ®µ
                    province = city = district = street = community = None

                    if row['level'] == 1:  # çœçº§
                        province = row['name']
                    elif row['level'] == 2:  # å¸‚çº§
                        city = row['name']
                    elif row['level'] == 3:  # å¿çº§
                        district = row['name']
                    elif row['level'] == 4:  # ä¹¡é•‡çº§
                        street = row['name']

                    # æ’å…¥æ•°æ®
                    insert_sql = '''
                    INSERT INTO regions (
                        code, name, parent_code, level, longitude, latitude,
                        pinyin, aliases, province, city, district, street,
                        community, data_source
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    '''

                    self.cursor.execute(insert_sql, (
                        row['code'], row['name'], row['parent_code'], row['level'],
                        row['longitude'], row['latitude'], row['pinyin'], row['aliases'],
                        province, city, district, street, community, 'legacy'
                    ))

                logger.info(f"âœ… å·²æ¢å¤ {len(backup_df)} æ¡ç°æœ‰æ•°æ®")

            except Exception as e:
                logger.error(f"æ¢å¤æ•°æ®å¤±è´¥: {e}")

    def download_national_data(self):
        """ä¸‹è½½å…¨å›½è¡Œæ”¿åŒºåˆ’æ•°æ®"""
        logger.info("å¼€å§‹ä¸‹è½½å…¨å›½è¡Œæ”¿åŒºåˆ’æ•°æ®...")

        # ä½¿ç”¨GitHubå¼€æºæ•°æ®æºï¼ˆæ›´æ˜“è·å–ä¸”æ ¼å¼è§„èŒƒï¼‰
        github_url = "https://raw.githubusercontent.com/modood/Administrative-divisions-of-China/master/dist/areas.json"

        try:
            response = requests.get(github_url, timeout=30)
            response.raise_for_status()

            data = response.json()
            logger.info(f"âœ… æˆåŠŸä¸‹è½½GitHubè¡Œæ”¿åŒºåˆ’æ•°æ®ï¼Œå…± {len(data)} æ¡è®°å½•")

            # ä¿å­˜åŸå§‹æ•°æ®
            with open('data/national_areas_raw.json', 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return data

        except Exception as e:
            logger.error(f"ä¸‹è½½GitHubæ•°æ®å¤±è´¥: {e}")
            return None

    def parse_and_insert_data(self, data: List[Dict]):
        """è§£æå¹¶æ’å…¥è¡Œæ”¿åŒºåˆ’æ•°æ®"""
        logger.info("å¼€å§‹è§£æå’Œæ’å…¥è¡Œæ”¿åŒºåˆ’æ•°æ®...")

        inserted_count = 0
        batch_size = 1000
        batch_data = []

        for item in data:
            try:
                # è§£ææ•°æ®ç»“æ„
                code = item.get('code', '')
                name = item.get('name', '')
                level = self.determine_level(code)
                parent_code = self.get_parent_code(code)

                # ç”Ÿæˆæ‹¼éŸ³ï¼ˆç®€å•å¤„ç†ï¼‰
                pinyin = self.generate_pinyin(name)

                # æ„å»ºå±‚çº§ä¿¡æ¯
                province, city, district, street, community = self.build_hierarchy_info(code, name, level)

                batch_data.append((
                    code, name, parent_code, level, None, None, pinyin, None,
                    province, city, district, street, community, None, 'github', 1.0
                ))

                if len(batch_data) >= batch_size:
                    self.insert_batch(batch_data)
                    inserted_count += len(batch_data)
                    batch_data = []
                    logger.info(f"å·²æ’å…¥ {inserted_count} æ¡è®°å½•...")

            except Exception as e:
                logger.warning(f"è§£ææ•°æ®é¡¹å¤±è´¥ {item}: {e}")

        # æ’å…¥å‰©ä½™æ•°æ®
        if batch_data:
            self.insert_batch(batch_data)
            inserted_count += len(batch_data)

        self.conn.commit()
        logger.info(f"âœ… æ•°æ®æ’å…¥å®Œæˆï¼Œå…±æ’å…¥ {inserted_count} æ¡è®°å½•")

    def determine_level(self, code: str) -> int:
        """æ ¹æ®åŒºåˆ’ä»£ç ç¡®å®šè¡Œæ”¿çº§åˆ«"""
        if not code or len(code) < 2:
            return 0

        # 12ä½ä»£ç çš„å±‚çº§è§„åˆ™
        if len(code) >= 2:
            # çœçº§ï¼šå‰2ä½
            if code[2:] == '0000000000':
                return 1
            # å¸‚çº§ï¼šå‰4ä½
            elif len(code) >= 4 and code[4:] == '00000000':
                return 2
            # å¿çº§ï¼šå‰6ä½
            elif len(code) >= 6 and code[6:] == '000000':
                return 3
            # ä¹¡çº§ï¼šå‰9ä½
            elif len(code) >= 9 and code[9:] == '000':
                return 4
            # æ‘çº§ï¼š12ä½å®Œæ•´ä»£ç 
            elif len(code) >= 12:
                return 5
            else:
                return 3  # é»˜è®¤ä¸ºå¿çº§

        return 0

    def get_parent_code(self, code: str) -> Optional[str]:
        """è·å–ä¸Šçº§åŒºåˆ’ä»£ç """
        if not code or len(code) < 2:
            return None

        level = self.determine_level(code)

        if level == 2:  # å¸‚çº§ï¼Œä¸Šçº§æ˜¯çœçº§
            return code[:2] + '0000000000'
        elif level == 3:  # å¿çº§ï¼Œä¸Šçº§æ˜¯å¸‚çº§
            return code[:4] + '00000000'
        elif level == 4:  # ä¹¡çº§ï¼Œä¸Šçº§æ˜¯å¿çº§
            return code[:6] + '000000'
        elif level == 5:  # æ‘çº§ï¼Œä¸Šçº§æ˜¯ä¹¡çº§
            return code[:9] + '000'
        else:
            return None

    def generate_pinyin(self, name: str) -> str:
        """ç”Ÿæˆæ‹¼éŸ³ï¼ˆç®€å•å¤„ç†ï¼Œåç»­å¯ä¼˜åŒ–ï¼‰"""
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„æ‹¼éŸ³ç”Ÿæˆï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨pypinyinç­‰åº“
        pinyin_map = {
            'åŒ—äº¬': 'beijing',
            'å¤©æ´¥': 'tianjin',
            'ä¸Šæµ·': 'shanghai',
            'é‡åº†': 'chongqing',
            'æ²³åŒ—': 'hebei',
            'å±±è¥¿': 'shanxi',
            'è¾½å®': 'liaoning',
            'å‰æ—': 'jilin',
            'é»‘é¾™æ±Ÿ': 'heilongjiang',
            'æ±Ÿè‹': 'jiangsu',
            'æµ™æ±Ÿ': 'zhejiang',
            'å®‰å¾½': 'anhui',
            'ç¦å»º': 'fujian',
            'æ±Ÿè¥¿': 'jiangxi',
            'å±±ä¸œ': 'shandong',
            'æ²³å—': 'henan',
            'æ¹–åŒ—': 'hubei',
            'æ¹–å—': 'hunan',
            'å¹¿ä¸œ': 'guangdong',
            'æµ·å—': 'hainan',
            'å››å·': 'sichuan',
            'è´µå·': 'guizhou',
            'äº‘å—': 'yunnan',
            'é™•è¥¿': 'shaanxi',
            'ç”˜è‚ƒ': 'gansu',
            'é’æµ·': 'qinghai',
            'å†…è’™å¤': 'neimenggu',
            'å¹¿è¥¿': 'guangxi',
            'è¥¿è—': 'xizang',
            'å®å¤': 'ningxia',
            'æ–°ç–†': 'xinjiang',
            'å°æ¹¾': 'taiwan',
            'é¦™æ¸¯': 'xianggang',
            'æ¾³é—¨': 'aomen'
        }

        return pinyin_map.get(name, name.lower())

    def build_hierarchy_info(self, code: str, name: str, level: int) -> Tuple:
        """æ„å»ºå±‚çº§ä¿¡æ¯"""
        province = city = district = street = community = None

        if level == 1:  # çœçº§
            province = name
        elif level == 2:  # å¸‚çº§
            city = name
        elif level == 3:  # å¿çº§
            district = name
        elif level == 4:  # ä¹¡çº§
            street = name
        elif level == 5:  # æ‘çº§
            community = name

        return province, city, district, street, community

    def insert_batch(self, batch_data: List[Tuple]):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        insert_sql = '''
        INSERT OR REPLACE INTO regions (
            code, name, parent_code, level, longitude, latitude, pinyin, aliases,
            province, city, district, street, community, urban_rural_type,
            data_source, data_quality
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        '''

        self.cursor.executemany(insert_sql, batch_data)

    def get_statistics(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}

        # æ€»æ•°ç»Ÿè®¡
        self.cursor.execute("SELECT COUNT(*) FROM regions")
        stats['total'] = self.cursor.fetchone()[0]

        # æŒ‰çº§åˆ«ç»Ÿè®¡
        self.cursor.execute("SELECT level, COUNT(*) FROM regions GROUP BY level ORDER BY level")
        level_stats = dict(self.cursor.fetchall())
        stats['by_level'] = level_stats

        # æŒ‰æ•°æ®æºç»Ÿè®¡
        self.cursor.execute("SELECT data_source, COUNT(*) FROM regions GROUP BY data_source")
        source_stats = dict(self.cursor.fetchall())
        stats['by_source'] = source_stats

        # æœ‰åæ ‡çš„ç»Ÿè®¡
        self.cursor.execute("SELECT COUNT(*) FROM regions WHERE longitude IS NOT NULL AND latitude IS NOT NULL")
        stats['with_coordinates'] = self.cursor.fetchone()[0]

        return stats

    def run_initialization(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®åº“åˆå§‹åŒ–æµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–å…¨å›½è¡Œæ”¿åŒºåˆ’æ•°æ®åº“...")

        try:
            # è¿æ¥æ•°æ®åº“
            self.connect()

            # åˆ›å»ºæ‰©å±•æ¶æ„
            self.create_extended_schema()

            # ä¸‹è½½æ•°æ®
            data = self.download_national_data()
            if data:
                # è§£æå¹¶æ’å…¥æ•°æ®
                self.parse_and_insert_data(data)

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats = self.get_statistics()
                logger.info("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
                logger.info(f"   æ€»è®°å½•æ•°: {stats['total']}")
                logger.info(f"   æŒ‰çº§åˆ«åˆ†å¸ƒ: {stats['by_level']}")
                logger.info(f"   æŒ‰æ•°æ®æºåˆ†å¸ƒ: {stats['by_source']}")
                logger.info(f"   æœ‰åæ ‡è®°å½•: {stats['with_coordinates']}")

                logger.info("âœ… å…¨å›½è¡Œæ”¿åŒºåˆ’æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
            else:
                logger.error("âŒ æ•°æ®ä¸‹è½½å¤±è´¥ï¼Œåˆå§‹åŒ–æœªå®Œæˆ")

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            raise
        finally:
            self.close()

def main():
    """ä¸»å‡½æ•°"""
    db = NationalRegionDatabase()
    db.run_initialization()

if __name__ == "__main__":
    main()